2025-09-20 23:24:20 - wind_shear:30 - INFO - WindShearDataset train split: 8935 scenes
2025-09-20 23:24:20 - wind_shear:30 - INFO - WindShearDataset val split: 2130 scenes
2025-09-20 23:24:20 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas4/v99_labeled.csv
2025-09-20 23:24:20 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas1/cc63_labeled.csv
2025-09-20 23:24:20 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas3/qq17_labeled.csv
2025-09-20 23:24:20 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas1/b159_labeled.csv
2025-09-20 23:24:20 - wind_shear:161 - DEBUG - [补点] v99_labeled.csv | 点数3595→3840（384的倍数）
2025-09-20 23:24:20 - wind_shear:161 - DEBUG - [补点] b159_labeled.csv | 点数4000→4224（384的倍数）
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas2/pp68_labeled.csv
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas1/c118_labeled.csv
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] qq17_labeled.csv | 点数4814→4992（384的倍数）
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] cc63_labeled.csv | 点数4915→4992（384的倍数）
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas1/cc157_labeled.csv
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (110)_labeled.csv
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] c118_labeled.csv | 点数3315→3456（384的倍数）
2025-09-20 23:24:21 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:21 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 23:24:21 - misc:366 - INFO -    各样本点数：[4224, 3456]（均为384的倍数）
2025-09-20 23:24:21 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 23:24:21 - misc:368 - INFO -    Offset：[0, 4224, 7680]
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas1/eeee (203)_labeled.csv
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] gggg (110)_labeled.csv | 点数4114→4224（384的倍数）
2025-09-20 23:24:21 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:21 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 23:24:21 - misc:366 - INFO -    各样本点数：[4992, 4224]（均为384的倍数）
2025-09-20 23:24:21 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 23:24:21 - misc:368 - INFO -    Offset：[0, 4992, 9216]
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] cc157_labeled.csv | 点数4148→4224（384的倍数）
2025-09-20 23:24:21 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:21 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 23:24:21 - misc:366 - INFO -    各样本点数：[4992, 4224]（均为384的倍数）
2025-09-20 23:24:21 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 23:24:21 - misc:368 - INFO -    Offset：[0, 4992, 9216]
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] pp68_labeled.csv | 点数6039→6144（384的倍数）
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas3/q88_labeled.csv
2025-09-20 23:24:21 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:21 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 23:24:21 - misc:366 - INFO -    各样本点数：[3840, 6144]（均为384的倍数）
2025-09-20 23:24:21 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 23:24:21 - misc:368 - INFO -    Offset：[0, 3840, 9984]
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas1/g40_labeled.csv
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas1/mm20_labeled.csv
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] eeee (203)_labeled.csv | 点数3129→3456（384的倍数）
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas2/iiii (132)_labeled.csv
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] q88_labeled.csv | 点数3565→3840（384的倍数）
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] g40_labeled.csv | 点数3847→4224（384的倍数）
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (53)_labeled.csv
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas1/mm118_labeled.csv
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] mm20_labeled.csv | 点数4259→4608（384的倍数）
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] iiii (132)_labeled.csv | 点数4425→4608（384的倍数）
2025-09-20 23:24:21 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:21 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 23:24:21 - misc:366 - INFO -    各样本点数：[3456, 4608]（均为384的倍数）
2025-09-20 23:24:21 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 23:24:21 - misc:368 - INFO -    Offset：[0, 3456, 8064]
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (158)_labeled.csv
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (150)_labeled.csv
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] mm118_labeled.csv | 点数3820→3840（384的倍数）
2025-09-20 23:24:21 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:21 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 23:24:21 - misc:366 - INFO -    各样本点数：[4224, 3840]（均为384的倍数）
2025-09-20 23:24:21 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 23:24:21 - misc:368 - INFO -    Offset：[0, 4224, 8064]
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] gggg (53)_labeled.csv | 点数4850→4992（384的倍数）
2025-09-20 23:24:21 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:21 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 23:24:21 - misc:366 - INFO -    各样本点数：[3840, 4992]（均为384的倍数）
2025-09-20 23:24:21 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 23:24:21 - misc:368 - INFO -    Offset：[0, 3840, 8832]
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] gggg (158)_labeled.csv | 点数5045→5376（384的倍数）
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas2/iiii (141)_labeled.csv
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] gggg (150)_labeled.csv | 点数4952→4992（384的倍数）
2025-09-20 23:24:21 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:21 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 23:24:21 - misc:366 - INFO -    各样本点数：[4608, 4992]（均为384的倍数）
2025-09-20 23:24:21 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 23:24:21 - misc:368 - INFO -    Offset：[0, 4608, 9600]
2025-09-20 23:24:21 - wind_shear:161 - DEBUG - [补点] iiii (141)_labeled.csv | 点数4671→4992（384的倍数）
2025-09-20 23:24:21 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:21 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=10368
2025-09-20 23:24:21 - misc:366 - INFO -    各样本点数：[5376, 4992]（均为384的倍数）
2025-09-20 23:24:21 - misc:367 - INFO -    拼接后维度：coord=torch.Size([10368, 3])，feat=torch.Size([10368, 9])，label=torch.Size([10368])
2025-09-20 23:24:21 - misc:368 - INFO -    Offset：[0, 5376, 10368]
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas3/k34_labeled.csv
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn52_labeled.csv
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas2/pp6_labeled.csv
2025-09-20 23:24:21 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas4/jj65_labeled.csv
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] k34_labeled.csv | 点数3767→3840（384的倍数）
2025-09-20 23:24:22 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas4/r17_labeled.csv
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] pp6_labeled.csv | 点数5170→5376（384的倍数）
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] jj65_labeled.csv | 点数4653→4992（384的倍数）
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] nn52_labeled.csv | 点数5331→5376（384的倍数）
2025-09-20 23:24:22 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas1/mm14_labeled.csv
2025-09-20 23:24:22 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas3/k17_labeled.csv
2025-09-20 23:24:22 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas2/z56_labeled.csv
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] r17_labeled.csv | 点数3278→3456（384的倍数）
2025-09-20 23:24:22 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:22 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 23:24:22 - misc:366 - INFO -    各样本点数：[3840, 3456]（均为384的倍数）
2025-09-20 23:24:22 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 23:24:22 - misc:368 - INFO -    Offset：[0, 3840, 7296]
2025-09-20 23:24:22 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas1/b4_labeled.csv
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] k17_labeled.csv | 点数3547→3840（384的倍数）
2025-09-20 23:24:22 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:22 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 23:24:22 - misc:366 - INFO -    各样本点数：[5376, 3840]（均为384的倍数）
2025-09-20 23:24:22 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 23:24:22 - misc:368 - INFO -    Offset：[0, 5376, 9216]
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] mm14_labeled.csv | 点数4143→4224（384的倍数）
2025-09-20 23:24:22 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:22 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 23:24:22 - misc:366 - INFO -    各样本点数：[4992, 4224]（均为384的倍数）
2025-09-20 23:24:22 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 23:24:22 - misc:368 - INFO -    Offset：[0, 4992, 9216]
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] z56_labeled.csv | 点数3779→3840（384的倍数）
2025-09-20 23:24:22 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:22 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 23:24:22 - misc:366 - INFO -    各样本点数：[5376, 3840]（均为384的倍数）
2025-09-20 23:24:22 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 23:24:22 - misc:368 - INFO -    Offset：[0, 5376, 9216]
2025-09-20 23:24:22 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas4/l43_labeled.csv
2025-09-20 23:24:22 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas1/aa166_labeled.csv
2025-09-20 23:24:22 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas2/dd68_labeled.csv
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] b4_labeled.csv | 点数4493→4608（384的倍数）
2025-09-20 23:24:22 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas2/ll60_labeled.csv
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] aa166_labeled.csv | 点数3929→4224（384的倍数）
2025-09-20 23:24:22 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas1/uu23_labeled.csv
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] l43_labeled.csv | 点数4756→4992（384的倍数）
2025-09-20 23:24:22 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas1/g185_labeled.csv
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] dd68_labeled.csv | 点数5785→6144（384的倍数）
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] uu23_labeled.csv | 点数1543→1920（384的倍数）
2025-09-20 23:24:22 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:22 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6144
2025-09-20 23:24:22 - misc:366 - INFO -    各样本点数：[4224, 1920]（均为384的倍数）
2025-09-20 23:24:22 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6144, 3])，feat=torch.Size([6144, 9])，label=torch.Size([6144])
2025-09-20 23:24:22 - misc:368 - INFO -    Offset：[0, 4224, 6144]
2025-09-20 23:24:22 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn99_labeled.csv
2025-09-20 23:24:22 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas1/ss37_labeled.csv
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] ll60_labeled.csv | 点数5874→6144（384的倍数）
2025-09-20 23:24:22 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:22 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=10752
2025-09-20 23:24:22 - misc:366 - INFO -    各样本点数：[4608, 6144]（均为384的倍数）
2025-09-20 23:24:22 - misc:367 - INFO -    拼接后维度：coord=torch.Size([10752, 3])，feat=torch.Size([10752, 9])，label=torch.Size([10752])
2025-09-20 23:24:22 - misc:368 - INFO -    Offset：[0, 4608, 10752]
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] ss37_labeled.csv | 点数1837→1920（384的倍数）
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:22 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] g185_labeled.csv | 点数4335→4608（384的倍数）
2025-09-20 23:24:22 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:22 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 23:24:22 - misc:366 - INFO -    各样本点数：[4992, 4608]（均为384的倍数）
2025-09-20 23:24:22 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 23:24:22 - misc:368 - INFO -    Offset：[0, 4992, 9600]
2025-09-20 23:24:22 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas2/h186_labeled.csv
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] nn99_labeled.csv | 点数5191→5376（384的倍数）
2025-09-20 23:24:22 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:22 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=11520
2025-09-20 23:24:22 - misc:366 - INFO -    各样本点数：[6144, 5376]（均为384的倍数）
2025-09-20 23:24:22 - misc:367 - INFO -    拼接后维度：coord=torch.Size([11520, 3])，feat=torch.Size([11520, 9])，label=torch.Size([11520])
2025-09-20 23:24:22 - misc:368 - INFO -    Offset：[0, 6144, 11520]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - wind_shear:161 - DEBUG - [补点] h186_labeled.csv | 点数3381→3456（384的倍数）
2025-09-20 23:24:22 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:22 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=5376
2025-09-20 23:24:22 - misc:366 - INFO -    各样本点数：[1920, 3456]（均为384的倍数）
2025-09-20 23:24:22 - misc:367 - INFO -    拼接后维度：coord=torch.Size([5376, 3])，feat=torch.Size([5376, 9])，label=torch.Size([5376])
2025-09-20 23:24:22 - misc:368 - INFO -    Offset：[0, 1920, 5376]
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:22 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 23:24:22 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6707
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6707
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6707]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6707, 64])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:22 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6707
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6707
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6707]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6707, 64])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:22 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 23:24:22 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2720]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2720, 128])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:22 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2720]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2720, 128])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:22 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2720]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2720, 128])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:22 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2720]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2720, 128])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:22 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2720]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2720, 128])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:22 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2720]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2720, 128])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 528], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 23:24:22 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 23:24:22 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=827，校正前pad范围: [0, 826]，校正后范围: [0, 826]
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 827
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 827
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([827]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([827, 256])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 528], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 23:24:22 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=827，校正前pad范围: [0, 826]，校正后范围: [0, 826]
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 827
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 827
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([827]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([827, 256])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:22 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2720]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2720, 128])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:22 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2720
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2720]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2720, 128])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:22 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6707
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6707
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6707]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6707, 64])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:22 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6707
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6707
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6707]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6707, 64])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:22 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:22 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:22 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:22 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:22 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:22 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:22 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:22 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:22 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:22 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:22 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:23 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:23 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:23 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:23 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 23:24:23 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:23 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:23 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:23 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:23 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:23 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:23 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:23 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:23 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:23 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:23 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:23 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:23 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:23 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:23 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:23 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:23 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:23 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:23 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:23 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:23 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:23 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:23 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 23:24:23 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:23 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:23 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:23 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6939
2025-09-20 23:24:23 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6939
2025-09-20 23:24:23 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:23 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:23 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6939]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:23 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6939, 64])
2025-09-20 23:24:23 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:23 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:23 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:23 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:23 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:23 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:23 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6939
2025-09-20 23:24:23 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6939
2025-09-20 23:24:23 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:23 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:23 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6939]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:23 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6939, 64])
2025-09-20 23:24:23 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas1/m51_labeled.csv
2025-09-20 23:24:23 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:23 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:23 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:23 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 23:24:23 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:23 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:23 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:23 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:23 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:23 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2928]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:23 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2928, 128])
2025-09-20 23:24:23 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:23 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:23 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:23 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:23 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:23 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:23 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:23 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:23 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2928]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:23 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2928, 128])
2025-09-20 23:24:23 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:23 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:23 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:23 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:23 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:23 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:23 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:23 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:23 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2928]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:23 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2928, 128])
2025-09-20 23:24:23 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:23 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:23 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:23 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:23 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:23 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:23 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:23 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:23 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2928]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:23 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2928, 128])
2025-09-20 23:24:23 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:23 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:23 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:23 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:23 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:23 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:23 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:23 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:23 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2928]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:23 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2928, 128])
2025-09-20 23:24:23 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:23 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:23 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:23 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:23 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:23 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:23 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:23 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:23 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2928]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:23 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2928, 128])
2025-09-20 23:24:23 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:23 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:23 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 480], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:23 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 23:24:23 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=879，校正前pad范围: [0, 878]，校正后范围: [0, 878]
2025-09-20 23:24:23 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:23 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:23 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 879
2025-09-20 23:24:23 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 879
2025-09-20 23:24:23 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:23 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:23 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([879]), 最大索引: 672, 最小索引: 0
2025-09-20 23:24:23 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([879, 256])
2025-09-20 23:24:23 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:23 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:23 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 480], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:23 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=879，校正前pad范围: [0, 878]，校正后范围: [0, 878]
2025-09-20 23:24:23 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:23 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:23 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 879
2025-09-20 23:24:23 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 879
2025-09-20 23:24:23 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:23 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:23 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([879]), 最大索引: 672, 最小索引: 0
2025-09-20 23:24:23 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([879, 256])
2025-09-20 23:24:23 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:23 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:23 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:23 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:23 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:23 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:23 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:23 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:23 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2928]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:23 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2928, 128])
2025-09-20 23:24:23 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:23 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:23 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:23 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:23 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:23 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:23 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:23 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:23 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:23 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2928
2025-09-20 23:24:23 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:23 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2928]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2928, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:24 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6939
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6939
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6939]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6939, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:24 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6939
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6939
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6939]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6939, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:24 - wind_shear:161 - DEBUG - [补点] m51_labeled.csv | 点数4335→4608（384的倍数）
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:24 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas2/d132_labeled.csv
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas2/dd24_labeled.csv
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4552，校正前pad范围: [0, 4551]，校正后范围: [0, 4551]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4552
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4552
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4552]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4552, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4552，校正前pad范围: [0, 4551]，校正后范围: [0, 4551]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4552
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4552
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4552]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4552, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1924，校正前pad范围: [0, 1923]，校正后范围: [0, 1923]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1924]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1924, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1924，校正前pad范围: [0, 1923]，校正后范围: [0, 1923]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1924]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1924, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1924，校正前pad范围: [0, 1923]，校正后范围: [0, 1923]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1924]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1924, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1924，校正前pad范围: [0, 1923]，校正后范围: [0, 1923]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1924]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1924, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1924，校正前pad范围: [0, 1923]，校正后范围: [0, 1923]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1924]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1924, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1924，校正前pad范围: [0, 1923]，校正后范围: [0, 1923]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1924]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1924, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 480], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=603，校正前pad范围: [0, 602]，校正后范围: [0, 602]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 603
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 603
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([603]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([603, 256])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 480], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=603，校正前pad范围: [0, 602]，校正后范围: [0, 602]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 603
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 603
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([603]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([603, 256])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1924，校正前pad范围: [0, 1923]，校正后范围: [0, 1923]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1924]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1924, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1924，校正前pad范围: [0, 1923]，校正后范围: [0, 1923]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1924
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1924]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1924, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4552，校正前pad范围: [0, 4551]，校正后范围: [0, 4551]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4552
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4552
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4552]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4552, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4552，校正前pad范围: [0, 4551]，校正后范围: [0, 4551]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4552
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4552
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4552]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4552, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:24 - wind_shear:161 - DEBUG - [补点] d132_labeled.csv | 点数4552→4608（384的倍数）
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 23:24:24 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas1/w114_labeled.csv
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:24 - wind_shear:161 - DEBUG - [补点] dd24_labeled.csv | 点数5781→6144（384的倍数）
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:24 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:24 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=10752
2025-09-20 23:24:24 - misc:366 - INFO -    各样本点数：[4608, 6144]（均为384的倍数）
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - misc:367 - INFO -    拼接后维度：coord=torch.Size([10752, 3])，feat=torch.Size([10752, 9])，label=torch.Size([10752])
2025-09-20 23:24:24 - misc:368 - INFO -    Offset：[0, 4608, 10752]
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas1/n55_labeled.csv
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 23:24:24 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5058
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5058
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5058]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5058, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:24 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5058
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5058
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5058]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5058, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 23:24:24 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1870]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1870, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:24 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1870]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1870, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:24 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1870]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1870, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:24 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1870]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1870, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:24 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1870]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1870, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:24 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1870]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1870, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 432], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=540，校正前pad范围: [0, 539]，校正后范围: [0, 539]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 540
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 540
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([540]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([540, 256])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 432], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=540，校正前pad范围: [0, 539]，校正后范围: [0, 539]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 540
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 540
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([540]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([540, 256])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:24 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1870]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1870, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:24 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1870
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1870]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1870, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:24 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5058
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5058
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5058]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5058, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:24 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5058
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5058
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5058]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - wind_shear:161 - DEBUG - [补点] n55_labeled.csv | 点数3541→3840（384的倍数）
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5058, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 23:24:24 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas3/u63_labeled.csv
2025-09-20 23:24:24 - wind_shear:161 - DEBUG - [补点] w114_labeled.csv | 点数3322→3456（384的倍数）
2025-09-20 23:24:24 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:24 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 23:24:24 - misc:366 - INFO -    各样本点数：[4608, 3456]（均为384的倍数）
2025-09-20 23:24:24 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 23:24:24 - misc:368 - INFO -    Offset：[0, 4608, 8064]
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 1920], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6144, unpad长度将设为=6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=960
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 32])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 1920], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=960
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 32])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112,  960], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3072, unpad长度将设为=3072
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2633，校正前pad范围: [0, 2632]，校正后范围: [0, 2632]
2025-09-20 23:24:24 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (72)_labeled.csv
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2633
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2633
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2633]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2633, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112,  960], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2633，校正前pad范围: [0, 2632]，校正后范围: [0, 2632]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2633
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2633
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2633]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2633, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1536, unpad长度将设为=1536
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1015，校正前pad范围: [0, 1014]，校正后范围: [0, 1014]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1015]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1015, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1015，校正前pad范围: [0, 1014]，校正后范围: [0, 1014]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1015]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1015, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1015，校正前pad范围: [0, 1014]，校正后范围: [0, 1014]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1015]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1015, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1015，校正前pad范围: [0, 1014]，校正后范围: [0, 1014]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1015]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1015, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1015，校正前pad范围: [0, 1014]，校正后范围: [0, 1014]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1015]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1015, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1015，校正前pad范围: [0, 1014]，校正后范围: [0, 1014]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1015]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1015, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 768], device='cuda:0')
2025-09-20 23:24:24 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 528, 768]
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 240], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 23:24:24 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 528, 768]
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=768, unpad长度将设为=768
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=314，校正前pad范围: [0, 313]，校正后范围: [0, 313]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 768], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(240, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数240，K=15
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 314
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 314
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([314]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([314, 256])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 768], device='cuda:0')
2025-09-20 23:24:24 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 528, 768]
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 240], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=314，校正前pad范围: [0, 313]，校正后范围: [0, 313]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 768], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(240, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数240，K=15
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 314
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 314
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([314]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([314, 256])
2025-09-20 23:24:24 - wind_shear:161 - DEBUG - [补点] u63_labeled.csv | 点数3555→3840（384的倍数）
2025-09-20 23:24:24 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:24 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 23:24:24 - misc:366 - INFO -    各样本点数：[3840, 3840]（均为384的倍数）
2025-09-20 23:24:24 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 23:24:24 - misc:368 - INFO -    Offset：[0, 3840, 7680]
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1015，校正前pad范围: [0, 1014]，校正后范围: [0, 1014]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1015]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1015, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1015，校正前pad范围: [0, 1014]，校正后范围: [0, 1014]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1015
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1015]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1015, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112,  960], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2633，校正前pad范围: [0, 2632]，校正后范围: [0, 2632]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2633
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2633
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2633]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2633, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112,  960], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2633，校正前pad范围: [0, 2632]，校正后范围: [0, 2632]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2633
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2633
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2633]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2633, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 1920], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 1920], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 23:24:24 - wind_shear:161 - DEBUG - [补点] gggg (72)_labeled.csv | 点数4867→4992（384的倍数）
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4177，校正前pad范围: [0, 4176]，校正后范围: [0, 4176]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4177
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4177
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4177]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4177, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:24 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas1/b114_labeled.csv
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4177，校正前pad范围: [0, 4176]，校正后范围: [0, 4176]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4177
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4177
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4177]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4177, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 23:24:24 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas2/z10_labeled.csv
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=532，校正前pad范围: [0, 531]，校正后范围: [0, 531]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 532
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 532
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([532]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([532, 256])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=532，校正前pad范围: [0, 531]，校正后范围: [0, 531]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 532
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 532
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([532]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([532, 256])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4177，校正前pad范围: [0, 4176]，校正后范围: [0, 4176]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4177
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4177
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4177]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4177, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4177，校正前pad范围: [0, 4176]，校正后范围: [0, 4176]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4177
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4177
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4177]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4177, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 23:24:24 - wind_shear:161 - DEBUG - [补点] z10_labeled.csv | 点数3406→3456（384的倍数）
2025-09-20 23:24:24 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:24 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 23:24:24 - misc:366 - INFO -    各样本点数：[4992, 3456]（均为384的倍数）
2025-09-20 23:24:24 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 23:24:24 - misc:368 - INFO -    Offset：[0, 4992, 8448]
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 5376], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 5376
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=11520, unpad长度将设为=11520
2025-09-20 23:24:24 - wind_shear:161 - DEBUG - [补点] b114_labeled.csv | 点数4675→4992（384的倍数）
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11520
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11520
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11520
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11520
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11520]), 最大索引: 6144, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11520, 32])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 5376], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 5376
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11520
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11520
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11520
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11520
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11520]), 最大索引: 6144, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11520, 32])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2688], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5760, unpad长度将设为=5760
2025-09-20 23:24:24 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas2/z135_labeled.csv
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5177，校正前pad范围: [0, 5176]，校正后范围: [0, 5176]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5177
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5177
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5177]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5177, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2688], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 23:24:24 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5177，校正前pad范围: [0, 5176]，校正后范围: [0, 5176]
2025-09-20 23:24:24 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:24 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:24 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:24 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5177
2025-09-20 23:24:24 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5177
2025-09-20 23:24:24 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:24 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:24 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5177]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:24 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:24 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5177, 64])
2025-09-20 23:24:24 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:24 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:24 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (170)_labeled.csv
2025-09-20 23:24:24 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 23:24:24 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:24 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2880, unpad长度将设为=2880
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2325，校正前pad范围: [0, 2324]，校正后范围: [0, 2324]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2325]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2325, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2325，校正前pad范围: [0, 2324]，校正后范围: [0, 2324]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2325]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2325, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2325，校正前pad范围: [0, 2324]，校正后范围: [0, 2324]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2325]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2325, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2325，校正前pad范围: [0, 2324]，校正后范围: [0, 2324]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2325]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2325, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2325，校正前pad范围: [0, 2324]，校正后范围: [0, 2324]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2325]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2325, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2325，校正前pad范围: [0, 2324]，校正后范围: [0, 2324]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2325]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2325, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1440], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 672], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1440, unpad长度将设为=1440
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=726，校正前pad范围: [0, 725]，校正后范围: [0, 725]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1440], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 726
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 726
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([726]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([726, 256])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1440], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 672], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=726，校正前pad范围: [0, 725]，校正后范围: [0, 725]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1440], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 726
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 726
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([726]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([726, 256])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2325，校正前pad范围: [0, 2324]，校正后范围: [0, 2324]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2325]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2325, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2325，校正前pad范围: [0, 2324]，校正后范围: [0, 2324]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2325
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2325]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2325, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5177，校正前pad范围: [0, 5176]，校正后范围: [0, 5176]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5177
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5177
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5177]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5177, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5177，校正前pad范围: [0, 5176]，校正后范围: [0, 5176]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5177
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5177
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5177]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5177, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11520
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11520
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11520
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11520
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11520]), 最大索引: 6144, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11520, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11520
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11520
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11520
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11520
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11520]), 最大索引: 6144, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11520, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 6144], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=10752, unpad长度将设为=10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=3072
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 32])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 6144], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=3072
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 32])
2025-09-20 23:24:25 - wind_shear:161 - DEBUG - [补点] gggg (170)_labeled.csv | 点数4656→4992（384的倍数）
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:25 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 23:24:25 - misc:366 - INFO -    各样本点数：[4992, 4992]（均为384的倍数）
2025-09-20 23:24:25 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 23:24:25 - misc:368 - INFO -    Offset：[0, 4992, 9984]
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3072], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5376, unpad长度将设为=5376
2025-09-20 23:24:25 - wind_shear:161 - DEBUG - [补点] z135_labeled.csv | 点数4397→4608（384的倍数）
2025-09-20 23:24:25 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas1/y109_labeled.csv
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5229，校正前pad范围: [0, 5228]，校正后范围: [0, 5228]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5229
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5229
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5229]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5229, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3072], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5229，校正前pad范围: [0, 5228]，校正后范围: [0, 5228]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5229
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5229
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5229]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5229, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2688, unpad长度将设为=2688
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2352，校正前pad范围: [0, 2351]，校正后范围: [0, 2351]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2352]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2352, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2352，校正前pad范围: [0, 2351]，校正后范围: [0, 2351]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2352]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2352, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2352，校正前pad范围: [0, 2351]，校正后范围: [0, 2351]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2352]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas4/bbbbb(144)_labeled.csv
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2352, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2352，校正前pad范围: [0, 2351]，校正后范围: [0, 2351]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2352]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2352, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2352，校正前pad范围: [0, 2351]，校正后范围: [0, 2351]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2352]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2352, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2352，校正前pad范围: [0, 2351]，校正后范围: [0, 2351]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2352]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2352, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 768], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1344, unpad长度将设为=1344
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=729，校正前pad范围: [0, 728]，校正后范围: [0, 728]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=48
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 729
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 729
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([729]), 最大索引: 576, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([729, 256])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 768], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=729，校正前pad范围: [0, 728]，校正后范围: [0, 728]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=48
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 729
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 729
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([729]), 最大索引: 576, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([729, 256])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2352，校正前pad范围: [0, 2351]，校正后范围: [0, 2351]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2352]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2352, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2352，校正前pad范围: [0, 2351]，校正后范围: [0, 2351]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2352
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2352]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2352, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3072], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5229，校正前pad范围: [0, 5228]，校正后范围: [0, 5228]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5229
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5229
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5229]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5229, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3072], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5229，校正前pad范围: [0, 5228]，校正后范围: [0, 5228]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5229
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5229
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5229]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5229, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 6144], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=1536
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 6144], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=1536
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 64])
2025-09-20 23:24:25 - wind_shear:161 - DEBUG - [补点] y109_labeled.csv | 点数3593→3840（384的倍数）
2025-09-20 23:24:25 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas1/aa153_labeled.csv
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3456], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5376, unpad长度将设为=5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5376]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5376, 32])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3456], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5376]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas2/j4_labeled.csv
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5376, 32])
2025-09-20 23:24:25 - wind_shear:161 - DEBUG - [补点] bbbbb(144)_labeled.csv | 点数3471→3840（384的倍数）
2025-09-20 23:24:25 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:25 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 23:24:25 - misc:366 - INFO -    各样本点数：[4608, 3840]（均为384的倍数）
2025-09-20 23:24:25 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 23:24:25 - misc:368 - INFO -    Offset：[0, 4608, 8448]
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1728], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2688, unpad长度将设为=2688
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2222，校正前pad范围: [0, 2221]，校正后范围: [0, 2221]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2222
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2222
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2222]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2222, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1728], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2222，校正前pad范围: [0, 2221]，校正后范围: [0, 2221]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2222
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2222
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2222]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2222, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1344, unpad长度将设为=1344
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=843，校正前pad范围: [0, 842]，校正后范围: [0, 842]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([843]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([843, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=843，校正前pad范围: [0, 842]，校正后范围: [0, 842]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([843]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([843, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=843，校正前pad范围: [0, 842]，校正后范围: [0, 842]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([843]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([843, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=843，校正前pad范围: [0, 842]，校正后范围: [0, 842]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([843]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([843, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=843，校正前pad范围: [0, 842]，校正后范围: [0, 842]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([843]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([843, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=843，校正前pad范围: [0, 842]，校正后范围: [0, 842]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([843]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([843, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 672], device='cuda:0')
2025-09-20 23:24:25 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 672]
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 432], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 23:24:25 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 672]
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=672, unpad长度将设为=672
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=267，校正前pad范围: [0, 266]，校正后范围: [0, 266]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 672], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 267
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 267
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([267]), 最大索引: 240, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([267, 256])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 672], device='cuda:0')
2025-09-20 23:24:25 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 672]
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 432], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=267，校正前pad范围: [0, 266]，校正后范围: [0, 266]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 672], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 267
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 267
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([267]), 最大索引: 240, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([267, 256])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=843，校正前pad范围: [0, 842]，校正后范围: [0, 842]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([843]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([843, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=843，校正前pad范围: [0, 842]，校正后范围: [0, 842]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 843
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([843]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([843, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1728], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2222，校正前pad范围: [0, 2221]，校正后范围: [0, 2221]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2222
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2222
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2222]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2222, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1728], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2222，校正前pad范围: [0, 2221]，校正后范围: [0, 2221]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2222
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2222
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2222]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2222, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3456], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5376]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5376, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3456], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5376]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5376, 64])
2025-09-20 23:24:25 - wind_shear:161 - DEBUG - [补点] j4_labeled.csv | 点数3700→3840（384的倍数）
2025-09-20 23:24:25 - wind_shear:161 - DEBUG - [补点] aa153_labeled.csv | 点数3985→4224（384的倍数）
2025-09-20 23:24:25 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:25 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 23:24:25 - misc:366 - INFO -    各样本点数：[3840, 4224]（均为384的倍数）
2025-09-20 23:24:25 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 23:24:25 - misc:368 - INFO -    Offset：[0, 3840, 8064]
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 6144], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=10752, unpad长度将设为=10752
2025-09-20 23:24:25 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas2/x107_labeled.csv
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=3072
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 32])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 6144], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=3072
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 32])
2025-09-20 23:24:25 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas1/y67_labeled.csv
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3072], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5376, unpad长度将设为=5376
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5376，校正前最大索引=5375, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7967
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7967
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7967]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7967, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3072], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5376，校正前最大索引=5375, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7967
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7967
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7967]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7967, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2688, unpad长度将设为=2688
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3435]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3435, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3435]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3435, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3435]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3435, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3435]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3435, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3435]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3435, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3435]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3435, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 768], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1344, unpad长度将设为=1344
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1050，校正前pad范围: [0, 1049]，校正后范围: [0, 1049]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=48
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1050
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1050
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1050]), 最大索引: 576, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1050, 256])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 768], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1050，校正前pad范围: [0, 1049]，校正后范围: [0, 1049]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1344], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=48
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1050
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1050
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1050]), 最大索引: 576, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1050, 256])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3435]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3435, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1536], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2688], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3435
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3435]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3435, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3072], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5376，校正前最大索引=5375, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7967
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7967
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7967]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7967, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3072], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5376，校正前最大索引=5375, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5376], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7967
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7967
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7967]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7967, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 6144], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=1536
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 6144], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4608, 10752], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=1536
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 64])
2025-09-20 23:24:25 - wind_shear:161 - DEBUG - [补点] x107_labeled.csv | 点数3705→3840（384的倍数）
2025-09-20 23:24:25 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:25 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 23:24:25 - misc:366 - INFO -    各样本点数：[3840, 3840]（均为384的倍数）
2025-09-20 23:24:25 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 23:24:25 - misc:368 - INFO -    Offset：[0, 3840, 7680]
2025-09-20 23:24:25 - wind_shear:161 - DEBUG - [补点] y67_labeled.csv | 点数3700→3840（384的倍数）
2025-09-20 23:24:25 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas2/bb178_labeled.csv
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:25 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas1/uu63_labeled.csv
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5987
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5987
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5987]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5987, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5987
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5987
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5987]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5987, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2349]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2349, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2349]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2349, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2349]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2349, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2349]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2349, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2349]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2349, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2349]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2349, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 432], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=706，校正前pad范围: [0, 705]，校正后范围: [0, 705]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 706
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 706
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([706]), 最大索引: 576, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([706, 256])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 432], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=706，校正前pad范围: [0, 705]，校正后范围: [0, 705]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 706
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 706
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([706]), 最大索引: 576, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([706, 256])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2349]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2349, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2349
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2349]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2349, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5987
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5987
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5987]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5987, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:25 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 23:24:25 - wind_shear:161 - DEBUG - [补点] uu63_labeled.csv | 点数2312→2688（384的倍数）
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5987
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5987
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5987]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5987, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:25 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas3/ii40_labeled.csv
2025-09-20 23:24:25 - wind_shear:161 - DEBUG - [补点] bb178_labeled.csv | 点数4717→4992（384的倍数）
2025-09-20 23:24:25 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:25 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 23:24:25 - misc:366 - INFO -    各样本点数：[3840, 4992]（均为384的倍数）
2025-09-20 23:24:25 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 23:24:25 - misc:368 - INFO -    Offset：[0, 3840, 8832]
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2512，校正前pad范围: [0, 2511]，校正后范围: [0, 2511]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2512
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2512
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2512]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas2/x198_labeled.csv
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2512, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2512，校正前pad范围: [0, 2511]，校正后范围: [0, 2511]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2512
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2512
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2512]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2512, 64])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=969，校正前pad范围: [0, 968]，校正后范围: [0, 968]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 969
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 969
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([969]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([969, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=969，校正前pad范围: [0, 968]，校正后范围: [0, 968]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 969
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 969
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([969]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([969, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=969，校正前pad范围: [0, 968]，校正后范围: [0, 968]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 969
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 969
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([969]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([969, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=969，校正前pad范围: [0, 968]，校正后范围: [0, 968]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 969
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 969
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([969]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([969, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=969，校正前pad范围: [0, 968]，校正后范围: [0, 968]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 969
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 969
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([969]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([969, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:25 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=969，校正前pad范围: [0, 968]，校正后范围: [0, 968]
2025-09-20 23:24:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 969
2025-09-20 23:24:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 969
2025-09-20 23:24:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([969]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([969, 128])
2025-09-20 23:24:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=305，校正前pad范围: [0, 304]，校正后范围: [0, 304]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 305
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 305
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([305]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([305, 256])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=305，校正前pad范围: [0, 304]，校正后范围: [0, 304]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 305
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 305
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([305]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([305, 256])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=969，校正前pad范围: [0, 968]，校正后范围: [0, 968]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 969
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 969
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([969]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([969, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=969，校正前pad范围: [0, 968]，校正后范围: [0, 968]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 969
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 969
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([969]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([969, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2512，校正前pad范围: [0, 2511]，校正后范围: [0, 2511]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2512
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2512
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2512]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2512, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2512，校正前pad范围: [0, 2511]，校正后范围: [0, 2511]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2512
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2512
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2512]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2512, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:26 - wind_shear:161 - DEBUG - [补点] ii40_labeled.csv | 点数3752→3840（384的倍数）
2025-09-20 23:24:26 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:26 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6528
2025-09-20 23:24:26 - misc:366 - INFO -    各样本点数：[2688, 3840]（均为384的倍数）
2025-09-20 23:24:26 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6528, 3])，feat=torch.Size([6528, 9])，label=torch.Size([6528])
2025-09-20 23:24:26 - misc:368 - INFO -    Offset：[0, 2688, 6528]
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3456], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3456], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas2/bb105_labeled.csv
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1728], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4226
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4226
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4226]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4226, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1728], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4226
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4226
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4226]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4226, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1752，校正前pad范围: [0, 1751]，校正后范围: [0, 1751]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1752]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1752, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:26 - wind_shear:161 - DEBUG - [补点] x198_labeled.csv | 点数5196→5376（384的倍数）
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1752，校正前pad范围: [0, 1751]，校正后范围: [0, 1751]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1752]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1752, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1752，校正前pad范围: [0, 1751]，校正后范围: [0, 1751]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1752]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1752, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1752，校正前pad范围: [0, 1751]，校正后范围: [0, 1751]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1752]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1752, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1752，校正前pad范围: [0, 1751]，校正后范围: [0, 1751]
2025-09-20 23:24:26 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas2/d169_labeled.csv
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1752]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1752, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1752，校正前pad范围: [0, 1751]，校正后范围: [0, 1751]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1752]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1752, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 432], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=550，校正前pad范围: [0, 549]，校正后范围: [0, 549]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 550
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 550
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([550]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([550, 256])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 432], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=550，校正前pad范围: [0, 549]，校正后范围: [0, 549]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 550
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 550
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([550]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([550, 256])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1752，校正前pad范围: [0, 1751]，校正后范围: [0, 1751]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1752]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1752, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1752，校正前pad范围: [0, 1751]，校正后范围: [0, 1751]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1752
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1752]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1752, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1728], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4226
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4226
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4226]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4226, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1728], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4226
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4226
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4226]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4226, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3456], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3456], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 23:24:26 - wind_shear:161 - DEBUG - [补点] bb105_labeled.csv | 点数3771→3840（384的倍数）
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:26 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas1/b140_labeled.csv
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 23:24:26 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas2/z97_labeled.csv
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4237，校正前pad范围: [0, 4236]，校正后范围: [0, 4236]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4237
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4237
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4237]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4237, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4237，校正前pad范围: [0, 4236]，校正后范围: [0, 4236]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4237
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4237
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4237]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4237, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1755，校正前pad范围: [0, 1754]，校正后范围: [0, 1754]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1755]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1755, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1755，校正前pad范围: [0, 1754]，校正后范围: [0, 1754]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1755]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1755, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1755，校正前pad范围: [0, 1754]，校正后范围: [0, 1754]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1755]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1755, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1755，校正前pad范围: [0, 1754]，校正后范围: [0, 1754]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1755]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1755, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1755，校正前pad范围: [0, 1754]，校正后范围: [0, 1754]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1755]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1755, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1755，校正前pad范围: [0, 1754]，校正后范围: [0, 1754]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1755]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1755, 128])
2025-09-20 23:24:26 - wind_shear:161 - DEBUG - [补点] d169_labeled.csv | 点数4456→4608（384的倍数）
2025-09-20 23:24:26 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:26 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 23:24:26 - misc:366 - INFO -    各样本点数：[5376, 4608]（均为384的倍数）
2025-09-20 23:24:26 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 23:24:26 - misc:368 - INFO -    Offset：[0, 5376, 9984]
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=550，校正前pad范围: [0, 549]，校正后范围: [0, 549]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 550
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 550
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([550]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([550, 256])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=550，校正前pad范围: [0, 549]，校正后范围: [0, 549]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 550
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 550
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([550]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([550, 256])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1755，校正前pad范围: [0, 1754]，校正后范围: [0, 1754]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1755]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1755, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1755，校正前pad范围: [0, 1754]，校正后范围: [0, 1754]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1755
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1755]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1755, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4237，校正前pad范围: [0, 4236]，校正后范围: [0, 4236]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4237
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4237
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4237]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4237, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4237，校正前pad范围: [0, 4236]，校正后范围: [0, 4236]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4237
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4237
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4237]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4237, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 23:24:26 - wind_shear:161 - DEBUG - [补点] z97_labeled.csv | 点数3504→3840（384的倍数）
2025-09-20 23:24:26 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas1/gg80_labeled.csv
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas1/hhhh (127)_labeled.csv
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5909
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5909
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5909]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5909, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5909
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5909
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5909]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5909, 64])
2025-09-20 23:24:26 - wind_shear:161 - DEBUG - [补点] b140_labeled.csv | 点数5162→5376（384的倍数）
2025-09-20 23:24:26 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:26 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 23:24:26 - misc:366 - INFO -    各样本点数：[3840, 5376]（均为384的倍数）
2025-09-20 23:24:26 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 23:24:26 - misc:368 - INFO -    Offset：[0, 3840, 9216]
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2292]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2292, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2292]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2292, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:26 - wind_shear:161 - DEBUG - [补点] gg80_labeled.csv | 点数2003→2304（384的倍数）
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:26 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6144
2025-09-20 23:24:26 - misc:366 - INFO -    各样本点数：[3840, 2304]（均为384的倍数）
2025-09-20 23:24:26 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6144, 3])，feat=torch.Size([6144, 9])，label=torch.Size([6144])
2025-09-20 23:24:26 - misc:368 - INFO -    Offset：[0, 3840, 6144]
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2292]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2292, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2292]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2292, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2292]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2292, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2292]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2292, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 480], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=682，校正前pad范围: [0, 681]，校正后范围: [0, 681]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 682
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 682
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([682]), 最大索引: 576, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([682, 256])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 480], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=682，校正前pad范围: [0, 681]，校正后范围: [0, 681]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 682
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 682
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([682]), 最大索引: 576, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([682, 256])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2292]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2292, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2292
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2292]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2292, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5909
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5909
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5909]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5909, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5909
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5909
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5909]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5909, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:26 - wind_shear:161 - DEBUG - [补点] hhhh (127)_labeled.csv | 点数3086→3456（384的倍数）
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 23:24:26 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas2/x118_labeled.csv
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:26 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas1/w167_labeled.csv
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2743，校正前pad范围: [0, 2742]，校正后范围: [0, 2742]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2743
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2743
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2743]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2743, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2743，校正前pad范围: [0, 2742]，校正后范围: [0, 2742]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2743
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2743
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2743]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2743, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1074，校正前pad范围: [0, 1073]，校正后范围: [0, 1073]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1074]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1074, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1074，校正前pad范围: [0, 1073]，校正后范围: [0, 1073]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1074]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1074, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1074，校正前pad范围: [0, 1073]，校正后范围: [0, 1073]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1074]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1074, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1074，校正前pad范围: [0, 1073]，校正后范围: [0, 1073]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1074]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1074, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1074，校正前pad范围: [0, 1073]，校正后范围: [0, 1073]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1074]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1074, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1074，校正前pad范围: [0, 1073]，校正后范围: [0, 1073]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1074]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1074, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 528], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=339，校正前pad范围: [0, 338]，校正后范围: [0, 338]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 339
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 339
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([339]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([339, 256])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 528], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=339，校正前pad范围: [0, 338]，校正后范围: [0, 338]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 339
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 339
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([339]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([339, 256])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1074，校正前pad范围: [0, 1073]，校正后范围: [0, 1073]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - wind_shear:161 - DEBUG - [补点] x118_labeled.csv | 点数3487→3840（384的倍数）
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1074]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1074, 128])
2025-09-20 23:24:26 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 23:24:26 - misc:366 - INFO -    各样本点数：[3456, 3840]（均为384的倍数）
2025-09-20 23:24:26 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 23:24:26 - misc:368 - INFO -    Offset：[0, 3456, 7296]
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1074，校正前pad范围: [0, 1073]，校正后范围: [0, 1073]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1074
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1074]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1074, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2743，校正前pad范围: [0, 2742]，校正后范围: [0, 2742]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2743
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2743
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2743]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2743, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2743，校正前pad范围: [0, 2742]，校正后范围: [0, 2742]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2743
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2743
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2743]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2743, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:26 - wind_shear:161 - DEBUG - [补点] w167_labeled.csv | 点数4136→4224（384的倍数）
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 23:24:26 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas1/y72_labeled.csv
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:26 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas2/vv159_labeled.csv
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5411
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5411
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5411]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5411, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5411
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5411
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5411]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5411, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2038]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2038, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2038]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2038, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2038]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2038, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2038]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2038, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2038]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2038, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2038]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2038, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=597，校正前pad范围: [0, 596]，校正后范围: [0, 596]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 597
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 597
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([597]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([597, 256])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:26 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=597，校正前pad范围: [0, 596]，校正后范围: [0, 596]
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 597
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 597
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([597]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([597, 256])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2038]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2038, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2038
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2038]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2038, 128])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5411
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5411
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5411]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5411, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:26 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5411
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5411
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5411]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5411, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 23:24:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:26 - wind_shear:161 - DEBUG - [补点] vv159_labeled.csv | 点数3185→3456（384的倍数）
2025-09-20 23:24:26 - wind_shear:161 - DEBUG - [补点] y72_labeled.csv | 点数3766→3840（384的倍数）
2025-09-20 23:24:26 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:26 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 23:24:26 - misc:366 - INFO -    各样本点数：[4224, 3840]（均为384的倍数）
2025-09-20 23:24:26 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 23:24:26 - misc:368 - INFO -    Offset：[0, 4224, 8064]
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 23:24:27 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas2/j103_labeled.csv
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 23:24:27 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas1/b118_labeled.csv
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6396
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6396
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6396]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6396, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6396
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6396
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6396]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6396, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2547]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2547, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2547]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2547, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2547]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2547, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2547]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2547, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2547]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2547, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2547]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2547, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 624], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=770，校正前pad范围: [0, 769]，校正后范围: [0, 769]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 770
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 770
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([770]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([770, 256])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 624], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=770，校正前pad范围: [0, 769]，校正后范围: [0, 769]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 770
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 770
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([770]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([770, 256])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2547]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2547, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2547
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2547]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2547, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6396
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6396
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6396]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6396, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6396
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6396
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6396]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6396, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 23:24:27 - wind_shear:161 - DEBUG - [补点] j103_labeled.csv | 点数3941→4224（384的倍数）
2025-09-20 23:24:27 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:27 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 23:24:27 - misc:366 - INFO -    各样本点数：[3456, 4224]（均为384的倍数）
2025-09-20 23:24:27 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 23:24:27 - misc:368 - INFO -    Offset：[0, 3456, 7680]
2025-09-20 23:24:27 - wind_shear:161 - DEBUG - [补点] b118_labeled.csv | 点数4053→4224（384的倍数）
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3840], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6528, unpad长度将设为=6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas4/r30_labeled.csv
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3840], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas1/b108_labeled.csv
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1920], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3264, unpad长度将设为=3264
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2502，校正前pad范围: [0, 2501]，校正后范围: [0, 2501]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2502
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2502
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2502]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2502, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1920], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2502，校正前pad范围: [0, 2501]，校正后范围: [0, 2501]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2502
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2502
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2502]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2502, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1632, unpad长度将设为=1632
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=959，校正前pad范围: [0, 958]，校正后范围: [0, 958]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([959]), 最大索引: 672, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([959, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=959，校正前pad范围: [0, 958]，校正后范围: [0, 958]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([959]), 最大索引: 672, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([959, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=959，校正前pad范围: [0, 958]，校正后范围: [0, 958]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([959]), 最大索引: 672, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([959, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=959，校正前pad范围: [0, 958]，校正后范围: [0, 958]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([959]), 最大索引: 672, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([959, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=959，校正前pad范围: [0, 958]，校正后范围: [0, 958]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([959]), 最大索引: 672, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([959, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=959，校正前pad范围: [0, 958]，校正后范围: [0, 958]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([959]), 最大索引: 672, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([959, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 816], device='cuda:0')
2025-09-20 23:24:27 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 816]
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 480], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 23:24:27 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 816]
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=816, unpad长度将设为=816
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=298，校正前pad范围: [0, 297]，校正后范围: [0, 297]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 816], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 298
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 298
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([298]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([298, 256])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 816], device='cuda:0')
2025-09-20 23:24:27 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 816]
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 480], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=298，校正前pad范围: [0, 297]，校正后范围: [0, 297]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 816], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 298
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 298
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([298]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([298, 256])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=959，校正前pad范围: [0, 958]，校正后范围: [0, 958]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([959]), 最大索引: 672, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([959, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=959，校正前pad范围: [0, 958]，校正后范围: [0, 958]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 959
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([959]), 最大索引: 672, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([959, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1920], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2502，校正前pad范围: [0, 2501]，校正后范围: [0, 2501]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2502
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2502
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2502]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2502, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1920], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2502，校正前pad范围: [0, 2501]，校正后范围: [0, 2501]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2502
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2502
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2502]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2502, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3840], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3840], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 23:24:27 - wind_shear:161 - DEBUG - [补点] r30_labeled.csv | 点数3298→3456（384的倍数）
2025-09-20 23:24:27 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:27 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 23:24:27 - misc:366 - INFO -    各样本点数：[4224, 3456]（均为384的倍数）
2025-09-20 23:24:27 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 23:24:27 - misc:368 - INFO -    Offset：[0, 4224, 7680]
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4608], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4608], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 23:24:27 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas3/q103_labeled.csv
2025-09-20 23:24:27 - wind_shear:161 - DEBUG - [补点] b108_labeled.csv | 点数5016→5376（384的倍数）
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4596，校正前pad范围: [0, 4595]，校正后范围: [0, 4595]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4596
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4596
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4596]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4596, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4596，校正前pad范围: [0, 4595]，校正后范围: [0, 4595]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4596
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4596
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4596]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4596, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1978，校正前pad范围: [0, 1977]，校正后范围: [0, 1977]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1978]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1978, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1978，校正前pad范围: [0, 1977]，校正后范围: [0, 1977]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:27 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas1/w173_labeled.csv
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1978]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1978, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1978，校正前pad范围: [0, 1977]，校正后范围: [0, 1977]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1978]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1978, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1978，校正前pad范围: [0, 1977]，校正后范围: [0, 1977]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1978]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1978, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1978，校正前pad范围: [0, 1977]，校正后范围: [0, 1977]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1978]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1978, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1978，校正前pad范围: [0, 1977]，校正后范围: [0, 1977]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1978]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1978, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1248], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 576], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=611，校正前pad范围: [0, 610]，校正后范围: [0, 610]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1248], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 611
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 611
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([611]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([611, 256])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1248], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 576], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=611，校正前pad范围: [0, 610]，校正后范围: [0, 610]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1248], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 611
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 611
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([611]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([611, 256])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1978，校正前pad范围: [0, 1977]，校正后范围: [0, 1977]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1978]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1978, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1978，校正前pad范围: [0, 1977]，校正后范围: [0, 1977]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1978
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1978]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1978, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4596，校正前pad范围: [0, 4595]，校正后范围: [0, 4595]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4596
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4596
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4596]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4596, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4596，校正前pad范围: [0, 4595]，校正后范围: [0, 4595]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4596
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4596
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4596]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4596, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4608], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4608], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 9216], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 5376], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 9216], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 9216], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 5376], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 9216], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - wind_shear:161 - DEBUG - [补点] w173_labeled.csv | 点数3961→4224（384的倍数）
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:27 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:27 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 23:24:27 - misc:366 - INFO -    各样本点数：[5376, 4224]（均为384的倍数）
2025-09-20 23:24:27 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 23:24:27 - misc:368 - INFO -    Offset：[0, 5376, 9600]
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:27 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas1/eeee (81)_labeled.csv
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2688], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4512，校正前pad范围: [0, 4511]，校正后范围: [0, 4511]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4512
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4512
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4512]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4512, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - wind_shear:161 - DEBUG - [补点] q103_labeled.csv | 点数4204→4224（384的倍数）
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2688], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4512，校正前pad范围: [0, 4511]，校正后范围: [0, 4511]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4512
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4512
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4512]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4512, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1344], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1912，校正前pad范围: [0, 1911]，校正后范围: [0, 1911]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1912]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1912, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1344], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1912，校正前pad范围: [0, 1911]，校正后范围: [0, 1911]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1912]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1912, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1344], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1912，校正前pad范围: [0, 1911]，校正后范围: [0, 1911]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1912]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1912, 128])
2025-09-20 23:24:27 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas1/y42_labeled.csv
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1344], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1912，校正前pad范围: [0, 1911]，校正后范围: [0, 1911]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1912]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1912, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1344], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1912，校正前pad范围: [0, 1911]，校正后范围: [0, 1911]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1912]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1912, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1344], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1912，校正前pad范围: [0, 1911]，校正后范围: [0, 1911]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1912]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1912, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 672], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=595，校正前pad范围: [0, 594]，校正后范围: [0, 594]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 595
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 595
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([595]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([595, 256])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 672], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=595，校正前pad范围: [0, 594]，校正后范围: [0, 594]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 595
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 595
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([595]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([595, 256])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1344], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1912，校正前pad范围: [0, 1911]，校正后范围: [0, 1911]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1912]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1912, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1344], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1912，校正前pad范围: [0, 1911]，校正后范围: [0, 1911]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1912
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1912]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1912, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2688], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4512，校正前pad范围: [0, 4511]，校正后范围: [0, 4511]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4512
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4512
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4512]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4512, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2688], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4512，校正前pad范围: [0, 4511]，校正后范围: [0, 4511]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4512
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4512
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4512]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4512, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 9216], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 5376], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 9216], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 9216], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 5376], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 9216], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6144], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:27 - wind_shear:161 - DEBUG - [补点] eeee (81)_labeled.csv | 点数4724→4992（384的倍数）
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6144, unpad长度将设为=6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6144], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 32])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6144], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6144], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 32])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3072], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3072, unpad长度将设为=3072
2025-09-20 23:24:27 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230316/datas1/ee16_labeled.csv
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2801，校正前pad范围: [0, 2800]，校正后范围: [0, 2800]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3072], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2801
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2801
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2801]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2801, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3072], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2801，校正前pad范围: [0, 2800]，校正后范围: [0, 2800]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3072], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2801
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2801
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2801]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - wind_shear:161 - DEBUG - [补点] y42_labeled.csv | 点数3696→3840（384的倍数）
2025-09-20 23:24:27 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas2/dd151_labeled.csv
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2801, 64])
2025-09-20 23:24:27 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:27 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 23:24:27 - misc:366 - INFO -    各样本点数：[4224, 3840]（均为384的倍数）
2025-09-20 23:24:27 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 23:24:27 - misc:368 - INFO -    Offset：[0, 4224, 8064]
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 576], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1536, unpad长度将设为=1536
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1064，校正前pad范围: [0, 1063]，校正后范围: [0, 1063]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1064]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1064, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 576], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1064，校正前pad范围: [0, 1063]，校正后范围: [0, 1063]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1064]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1064, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 576], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1064，校正前pad范围: [0, 1063]，校正后范围: [0, 1063]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1064]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1064, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 576], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1064，校正前pad范围: [0, 1063]，校正后范围: [0, 1063]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1064]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1064, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 576], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1064，校正前pad范围: [0, 1063]，校正后范围: [0, 1063]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1064]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1064, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 576], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1064，校正前pad范围: [0, 1063]，校正后范围: [0, 1063]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1064]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1064, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 768], device='cuda:0')
2025-09-20 23:24:27 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为288（小于384），offset=[0, 480, 768]
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 288], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 23:24:27 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为288（小于384），offset=[0, 480, 768]
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=768, unpad长度将设为=768
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=332，校正前pad范围: [0, 331]，校正后范围: [0, 331]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 768], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(288, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数288，K=18
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 332
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 332
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([332]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([332, 256])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 768], device='cuda:0')
2025-09-20 23:24:27 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为288（小于384），offset=[0, 480, 768]
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 288], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=332，校正前pad范围: [0, 331]，校正后范围: [0, 331]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 768], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(288, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数288，K=18
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 332
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 332
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([332]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([332, 256])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 576], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1064，校正前pad范围: [0, 1063]，校正后范围: [0, 1063]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1064]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1064, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 576], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1064，校正前pad范围: [0, 1063]，校正后范围: [0, 1063]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1536], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1064
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1064]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1064, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3072], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2801，校正前pad范围: [0, 2800]，校正后范围: [0, 2800]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3072], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2801
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2801
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2801]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2801, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3072], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1152], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2801，校正前pad范围: [0, 2800]，校正后范围: [0, 2800]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3072], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2801
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2801
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2801]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2801, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6144], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6144], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6144], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 2304], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6144], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:27 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas1/cc8_labeled.csv
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4751
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4751
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4751]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4751, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4751
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4751
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4751]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4751, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - wind_shear:161 - DEBUG - [补点] dd151_labeled.csv | 点数4847→4992（384的倍数）
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 23:24:27 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:27 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 23:24:27 - misc:366 - INFO -    各样本点数：[4992, 4992]（均为384的倍数）
2025-09-20 23:24:27 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 23:24:27 - misc:368 - INFO -    Offset：[0, 4992, 9984]
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - wind_shear:161 - DEBUG - [补点] ee16_labeled.csv | 点数5438→5760（384的倍数）
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 480], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=526，校正前pad范围: [0, 525]，校正后范围: [0, 525]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 526
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 526
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([526]), 最大索引: 432, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([526, 256])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 480], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=526，校正前pad范围: [0, 525]，校正后范围: [0, 525]
2025-09-20 23:24:27 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas2/o197_labeled.csv
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 526
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 526
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([526]), 最大索引: 432, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([526, 256])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:27 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4751
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4751
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4751]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4751, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:27 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4751
2025-09-20 23:24:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4751
2025-09-20 23:24:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4751]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4751, 64])
2025-09-20 23:24:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 23:24:28 - wind_shear:161 - DEBUG - [补点] cc8_labeled.csv | 点数4691→4992（384的倍数）
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 23:24:28 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas2/d184_labeled.csv
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2907，校正前pad范围: [0, 2906]，校正后范围: [0, 2906]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:28 - wind_shear:161 - DEBUG - [补点] o197_labeled.csv | 点数3287→3456（384的倍数）
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2907
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2907
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2907]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:28 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 23:24:28 - misc:366 - INFO -    各样本点数：[5760, 3456]（均为384的倍数）
2025-09-20 23:24:28 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 23:24:28 - misc:368 - INFO -    Offset：[0, 5760, 9216]
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2907, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 23:24:28 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas4/l29_labeled.csv
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2907，校正前pad范围: [0, 2906]，校正后范围: [0, 2906]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2907
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2907
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2907]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2907, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1141，校正前pad范围: [0, 1140]，校正后范围: [0, 1140]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1141]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1141, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1141，校正前pad范围: [0, 1140]，校正后范围: [0, 1140]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1141]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1141, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1141，校正前pad范围: [0, 1140]，校正后范围: [0, 1140]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1141]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1141, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1141，校正前pad范围: [0, 1140]，校正后范围: [0, 1140]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1141]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1141, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1141，校正前pad范围: [0, 1140]，校正后范围: [0, 1140]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1141]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1141, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1141，校正前pad范围: [0, 1140]，校正后范围: [0, 1140]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1141]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1141, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 480], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=364，校正前pad范围: [0, 363]，校正后范围: [0, 363]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 364
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 364
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([364]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([364, 256])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 480], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=364，校正前pad范围: [0, 363]，校正后范围: [0, 363]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 364
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 364
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([364]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([364, 256])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1141，校正前pad范围: [0, 1140]，校正后范围: [0, 1140]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1141]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1141, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1141，校正前pad范围: [0, 1140]，校正后范围: [0, 1140]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1141
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1141]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1141, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2907，校正前pad范围: [0, 2906]，校正后范围: [0, 2906]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2907
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2907
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2907]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2907, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2907，校正前pad范围: [0, 2906]，校正后范围: [0, 2906]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2907
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2907
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2907]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2907, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 23:24:28 - wind_shear:161 - DEBUG - [补点] d184_labeled.csv | 点数4394→4608（384的倍数）
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 23:24:28 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas1/w203_labeled.csv
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5089
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5089
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5089]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5089, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5089
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5089
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5089]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5089, 64])
2025-09-20 23:24:28 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas2/o129_labeled.csv
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:28 - wind_shear:161 - DEBUG - [补点] l29_labeled.csv | 点数5071→5376（384的倍数）
2025-09-20 23:24:28 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:28 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=10368
2025-09-20 23:24:28 - misc:366 - INFO -    各样本点数：[4992, 5376]（均为384的倍数）
2025-09-20 23:24:28 - misc:367 - INFO -    拼接后维度：coord=torch.Size([10368, 3])，feat=torch.Size([10368, 9])，label=torch.Size([10368])
2025-09-20 23:24:28 - misc:368 - INFO -    Offset：[0, 4992, 10368]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 528], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=561，校正前pad范围: [0, 560]，校正后范围: [0, 560]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 561
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 561
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([561]), 最大索引: 432, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([561, 256])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 528], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=561，校正前pad范围: [0, 560]，校正后范围: [0, 560]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 561
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 561
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([561]), 最大索引: 432, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([561, 256])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5089
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5089
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5089]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5089, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5089
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5089
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5089]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5089, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - wind_shear:161 - DEBUG - [补点] w203_labeled.csv | 点数3974→4224（384的倍数）
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 23:24:28 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas2/bb118_labeled.csv
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3400，校正前pad范围: [0, 3399]，校正后范围: [0, 3399]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:28 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas2/dd38_labeled.csv
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3400
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3400
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3400]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3400, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3400，校正前pad范围: [0, 3399]，校正后范围: [0, 3399]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3400
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3400
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3400]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3400, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1325，校正前pad范围: [0, 1324]，校正后范围: [0, 1324]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1325
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1325
2025-09-20 23:24:28 - wind_shear:161 - DEBUG - [补点] o129_labeled.csv | 点数4291→4608（384的倍数）
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1325]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1325, 128])
2025-09-20 23:24:28 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:28 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 23:24:28 - misc:366 - INFO -    各样本点数：[4608, 4608]（均为384的倍数）
2025-09-20 23:24:28 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - misc:368 - INFO -    Offset：[0, 4608, 9216]
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1325，校正前pad范围: [0, 1324]，校正后范围: [0, 1324]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1325
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1325
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1325]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1325, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1325，校正前pad范围: [0, 1324]，校正后范围: [0, 1324]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1325
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1325
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1325]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1325, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1325，校正前pad范围: [0, 1324]，校正后范围: [0, 1324]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1325
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1325
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1325]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1325, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1325，校正前pad范围: [0, 1324]，校正后范围: [0, 1324]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1325
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1325
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1325]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1325, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1325，校正前pad范围: [0, 1324]，校正后范围: [0, 1324]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1325
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1325
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1325]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1325, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 432], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=401，校正前pad范围: [0, 400]，校正后范围: [0, 400]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 401
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 401
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([401]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([401, 256])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 432], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=401，校正前pad范围: [0, 400]，校正后范围: [0, 400]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 401
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 401
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([401]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([401, 256])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1325，校正前pad范围: [0, 1324]，校正后范围: [0, 1324]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1325
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1325
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1325]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1325, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1325，校正前pad范围: [0, 1324]，校正后范围: [0, 1324]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1325
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1325
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1325]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1325, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3400，校正前pad范围: [0, 3399]，校正后范围: [0, 3399]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3400
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3400
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3400]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3400, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3400，校正前pad范围: [0, 3399]，校正后范围: [0, 3399]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3400
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3400
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3400]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3400, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:28 - wind_shear:161 - DEBUG - [补点] bb118_labeled.csv | 点数3262→3456（384的倍数）
2025-09-20 23:24:28 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:28 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 23:24:28 - misc:366 - INFO -    各样本点数：[4224, 3456]（均为384的倍数）
2025-09-20 23:24:28 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 23:24:28 - misc:368 - INFO -    Offset：[0, 4224, 7680]
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 23:24:28 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas2/a139_labeled.csv
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6928
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6928
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6928]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6928, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6928
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6928
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6928]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6928, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2837]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2837, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2837]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2837, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2837]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2837, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2837]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2837, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2837]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2837, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2837]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2837, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 528], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=854，校正前pad范围: [0, 853]，校正后范围: [0, 853]
2025-09-20 23:24:28 - wind_shear:161 - DEBUG - [补点] dd38_labeled.csv | 点数5920→6144（384的倍数）
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 854
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 854
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([854]), 最大索引: 672, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([854, 256])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 528], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=854，校正前pad范围: [0, 853]，校正后范围: [0, 853]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 854
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 854
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([854]), 最大索引: 672, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([854, 256])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2837]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2837, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2837
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2837]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2837, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6928
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6928
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6928]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6928, 64])
2025-09-20 23:24:28 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas1/mm75_labeled.csv
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6928
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6928
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6928]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6928, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 23:24:28 - wind_shear:161 - DEBUG - [补点] a139_labeled.csv | 点数3293→3456（384的倍数）
2025-09-20 23:24:28 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas2/h133_labeled.csv
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 23:24:28 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas1/oo59_labeled.csv
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2859，校正前pad范围: [0, 2858]，校正后范围: [0, 2858]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2859
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2859
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2859]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2859, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2859，校正前pad范围: [0, 2858]，校正后范围: [0, 2858]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2859
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2859
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2859]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2859, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1153，校正前pad范围: [0, 1152]，校正后范围: [0, 1152]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1153]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1153, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1153，校正前pad范围: [0, 1152]，校正后范围: [0, 1152]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1153]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1153, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1153，校正前pad范围: [0, 1152]，校正后范围: [0, 1152]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1153]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1153, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1153，校正前pad范围: [0, 1152]，校正后范围: [0, 1152]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1153]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1153, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1153，校正前pad范围: [0, 1152]，校正后范围: [0, 1152]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1153]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1153, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1153，校正前pad范围: [0, 1152]，校正后范围: [0, 1152]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1153]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1153, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 480], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=355，校正前pad范围: [0, 354]，校正后范围: [0, 354]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 355
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 355
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([355]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([355, 256])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 480], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=355，校正前pad范围: [0, 354]，校正后范围: [0, 354]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 355
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 355
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([355]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([355, 256])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1153，校正前pad范围: [0, 1152]，校正后范围: [0, 1152]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1153]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1153, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1153，校正前pad范围: [0, 1152]，校正后范围: [0, 1152]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1153
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1153]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1153, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2859，校正前pad范围: [0, 2858]，校正后范围: [0, 2858]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2859
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2859
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2859]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2859, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:28 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2859，校正前pad范围: [0, 2858]，校正后范围: [0, 2858]
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2859
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2859
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2859]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - wind_shear:161 - DEBUG - [补点] mm75_labeled.csv | 点数4781→4992（384的倍数）
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2859, 64])
2025-09-20 23:24:28 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:28 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=11136
2025-09-20 23:24:28 - misc:366 - INFO -    各样本点数：[6144, 4992]（均为384的倍数）
2025-09-20 23:24:28 - misc:367 - INFO -    拼接后维度：coord=torch.Size([11136, 3])，feat=torch.Size([11136, 9])，label=torch.Size([11136])
2025-09-20 23:24:28 - misc:368 - INFO -    Offset：[0, 6144, 11136]
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:28 - wind_shear:161 - DEBUG - [补点] h133_labeled.csv | 点数3605→3840（384的倍数）
2025-09-20 23:24:28 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:28 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 23:24:28 - misc:366 - INFO -    各样本点数：[3456, 3840]（均为384的倍数）
2025-09-20 23:24:28 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 23:24:28 - misc:368 - INFO -    Offset：[0, 3456, 7296]
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:28 - wind_shear:161 - DEBUG - [补点] oo59_labeled.csv | 点数4628→4992（384的倍数）
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:28 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas2/hh85_labeled.csv
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7383
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7383
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7383]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7383, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:28 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas2/x177_labeled.csv
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7383
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7383
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7383]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7383, 64])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3052
2025-09-20 23:24:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3052
2025-09-20 23:24:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3052]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3052, 128])
2025-09-20 23:24:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:28 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 23:24:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3052
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3052
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3052]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3052, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3052
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3052
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3052]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3052, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3052
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3052
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3052]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3052, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3052
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3052
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3052]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3052, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3052
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3052
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3052]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3052, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=919，校正前pad范围: [0, 918]，校正后范围: [0, 918]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 919
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 919
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([919]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([919, 256])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=919，校正前pad范围: [0, 918]，校正后范围: [0, 918]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 919
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 919
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([919]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([919, 256])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3052
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3052
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3052]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3052, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - wind_shear:161 - DEBUG - [补点] hh85_labeled.csv | 点数1760→1920（384的倍数）
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3052
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3052
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3052]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3052, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7383
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7383
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7383]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7383, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7383
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7383
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7383]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7383, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:29 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas1/ss95_labeled.csv
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 23:24:29 - wind_shear:161 - DEBUG - [补点] x177_labeled.csv | 点数4544→4608（384的倍数）
2025-09-20 23:24:29 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:29 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 23:24:29 - misc:366 - INFO -    各样本点数：[4992, 4608]（均为384的倍数）
2025-09-20 23:24:29 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 23:24:29 - misc:368 - INFO -    Offset：[0, 4992, 9600]
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:29 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas1/oo35_labeled.csv
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4779
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4779
2025-09-20 23:24:29 - wind_shear:161 - DEBUG - [补点] ss95_labeled.csv | 点数2607→2688（384的倍数）
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4779]), 最大索引: 2880, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:29 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=4608
2025-09-20 23:24:29 - misc:366 - INFO -    各样本点数：[1920, 2688]（均为384的倍数）
2025-09-20 23:24:29 - misc:367 - INFO -    拼接后维度：coord=torch.Size([4608, 3])，feat=torch.Size([4608, 9])，label=torch.Size([4608])
2025-09-20 23:24:29 - misc:368 - INFO -    Offset：[0, 1920, 4608]
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4779, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4779
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4779
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4779]), 最大索引: 2880, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4779, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2070，校正前pad范围: [0, 2069]，校正后范围: [0, 2069]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2070]), 最大索引: 1440, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2070, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2070，校正前pad范围: [0, 2069]，校正后范围: [0, 2069]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2070]), 最大索引: 1440, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2070, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2070，校正前pad范围: [0, 2069]，校正后范围: [0, 2069]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2070]), 最大索引: 1440, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2070, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2070，校正前pad范围: [0, 2069]，校正后范围: [0, 2069]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2070]), 最大索引: 1440, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2070, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2070，校正前pad范围: [0, 2069]，校正后范围: [0, 2069]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2070]), 最大索引: 1440, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2070, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2070，校正前pad范围: [0, 2069]，校正后范围: [0, 2069]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2070]), 最大索引: 1440, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2070, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 432], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=658，校正前pad范围: [0, 657]，校正后范围: [0, 657]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 658
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 658
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([658]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([658, 256])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 432], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=658，校正前pad范围: [0, 657]，校正后范围: [0, 657]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 658
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 658
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([658]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([658, 256])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2070，校正前pad范围: [0, 2069]，校正后范围: [0, 2069]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2070]), 最大索引: 1440, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2070, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2070，校正前pad范围: [0, 2069]，校正后范围: [0, 2069]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2070
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2070]), 最大索引: 1440, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2070, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4779
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4779
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4779]), 最大索引: 2880, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4779, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4779
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4779
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4779]), 最大索引: 2880, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4779, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4992, 10368], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 5376], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=10368, unpad长度将设为=10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4992, 10368], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 32])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4992, 10368], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 5376], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4992, 10368], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 32])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 5184], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2688], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5184, unpad长度将设为=5184
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5184，校正前最大索引=5183, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 5184], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7554
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7554
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7554]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas3/ii96_labeled.csv
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7554, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 5184], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2688], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5184，校正前最大索引=5183, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 5184], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7554
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7554
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7554]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7554, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1344], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2592, unpad长度将设为=2592
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2592，校正前最大索引=2591, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3162]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3162, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1344], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - wind_shear:161 - DEBUG - [补点] oo35_labeled.csv | 点数4795→4992（384的倍数）
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2592，校正前最大索引=2591, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3162]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3162, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1344], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2592，校正前最大索引=2591, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3162]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3162, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1344], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2592，校正前最大索引=2591, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3162]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3162, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1344], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2592，校正前最大索引=2591, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3162]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3162, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1344], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2592，校正前最大索引=2591, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3162]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3162, 128])
2025-09-20 23:24:29 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn25_labeled.csv
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1296], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 672], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1296, unpad长度将设为=1296
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=962，校正前pad范围: [0, 961]，校正后范围: [0, 961]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1296], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 962
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 962
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([962]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([962, 256])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1296], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 672], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=962，校正前pad范围: [0, 961]，校正后范围: [0, 961]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1296], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 962
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 962
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([962]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([962, 256])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1344], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2592，校正前最大索引=2591, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3162]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3162, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1344], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2592，校正前最大索引=2591, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2592], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3162
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3162]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3162, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 5184], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2688], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5184，校正前最大索引=5183, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 5184], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7554
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7554
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7554]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7554, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 5184], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2688], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5184，校正前最大索引=5183, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 5184], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7554
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7554
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7554]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7554, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4992, 10368], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 5376], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4992, 10368], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4992, 10368], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 5376], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4992, 10368], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3954，校正前pad范围: [0, 3953]，校正后范围: [0, 3953]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 23:24:29 - wind_shear:161 - DEBUG - [补点] ii96_labeled.csv | 点数4725→4992（384的倍数）
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3954
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3954
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3954]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3954, 64])
2025-09-20 23:24:29 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas3/u11_labeled.csv
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3954，校正前pad范围: [0, 3953]，校正后范围: [0, 3953]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3954
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3954
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3954]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3954, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1623，校正前pad范围: [0, 1622]，校正后范围: [0, 1622]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1623]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1623, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1623，校正前pad范围: [0, 1622]，校正后范围: [0, 1622]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1623]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1623, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1623，校正前pad范围: [0, 1622]，校正后范围: [0, 1622]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1623]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1623, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1623，校正前pad范围: [0, 1622]，校正后范围: [0, 1622]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1623]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1623, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1623，校正前pad范围: [0, 1622]，校正后范围: [0, 1622]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1623]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1623, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1623，校正前pad范围: [0, 1622]，校正后范围: [0, 1622]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1623]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1623, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 576], device='cuda:0')
2025-09-20 23:24:29 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas1/aa210_labeled.csv
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=492，校正前pad范围: [0, 491]，校正后范围: [0, 491]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 492
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 492
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([492]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([492, 256])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 576], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=492，校正前pad范围: [0, 491]，校正后范围: [0, 491]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 492
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 492
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([492]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([492, 256])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1623，校正前pad范围: [0, 1622]，校正后范围: [0, 1622]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1623]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - wind_shear:161 - DEBUG - [补点] nn25_labeled.csv | 点数5662→5760（384的倍数）
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1623, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:29 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=10752
2025-09-20 23:24:29 - misc:366 - INFO -    各样本点数：[4992, 5760]（均为384的倍数）
2025-09-20 23:24:29 - misc:367 - INFO -    拼接后维度：coord=torch.Size([10752, 3])，feat=torch.Size([10752, 9])，label=torch.Size([10752])
2025-09-20 23:24:29 - misc:368 - INFO -    Offset：[0, 4992, 10752]
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1623，校正前pad范围: [0, 1622]，校正后范围: [0, 1622]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1623
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1623]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1623, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3954，校正前pad范围: [0, 3953]，校正后范围: [0, 3953]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3954
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3954
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3954]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3954, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3954，校正前pad范围: [0, 3953]，校正后范围: [0, 3953]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3954
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3954
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3954]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3954, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 23:24:29 - wind_shear:161 - DEBUG - [补点] u11_labeled.csv | 点数4133→4224（384的倍数）
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5181
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5181
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5181]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas2/iiii (86)_labeled.csv
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5181, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5181
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5181
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5181]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5181, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1973]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1973, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:29 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas1/y130_labeled.csv
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1973]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1973, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1973]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1973, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1973]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1973, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1973]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1973, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:29 - wind_shear:161 - DEBUG - [补点] aa210_labeled.csv | 点数4795→4992（384的倍数）
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1973]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:29 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - misc:366 - INFO -    各样本点数：[4992, 4992]（均为384的倍数）
2025-09-20 23:24:29 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 23:24:29 - misc:368 - INFO -    Offset：[0, 4992, 9984]
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1973, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 432], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=579，校正前pad范围: [0, 578]，校正后范围: [0, 578]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 579
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 579
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([579]), 最大索引: 528, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([579, 256])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 432], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=579，校正前pad范围: [0, 578]，校正后范围: [0, 578]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 579
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 579
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([579]), 最大索引: 528, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([579, 256])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1973]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1973, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1973
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1973]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1973, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5181
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5181
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5181]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5181, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5181
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5181
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5181]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5181, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4992], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=11136, unpad长度将设为=11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11136]), 最大索引: 6144, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11136, 32])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4992], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:29 - wind_shear:161 - DEBUG - [补点] y130_labeled.csv | 点数3555→3840（384的倍数）
2025-09-20 23:24:29 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:29 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 23:24:29 - misc:366 - INFO -    各样本点数：[4224, 3840]（均为384的倍数）
2025-09-20 23:24:29 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 23:24:29 - misc:368 - INFO -    Offset：[0, 4224, 8064]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11136]), 最大索引: 6144, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11136, 32])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5568, unpad长度将设为=5568
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5568，校正前最大索引=5567, 最小索引=0
2025-09-20 23:24:29 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230316/datas1/ee2_labeled.csv
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8465
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8465
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8465]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8465, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5568，校正前最大索引=5567, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8465
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8465
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8465]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8465, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2784, unpad长度将设为=2784
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2784，校正前最大索引=2783, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3739]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3739, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2784，校正前最大索引=2783, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3739]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3739, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2784，校正前最大索引=2783, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3739]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3739, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - wind_shear:161 - DEBUG - [补点] iiii (86)_labeled.csv | 点数5104→5376（384的倍数）
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2784，校正前最大索引=2783, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3739]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3739, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2784，校正前最大索引=2783, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3739]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3739, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2784，校正前最大索引=2783, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3739]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3739, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1392], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 624], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1392, unpad长度将设为=1392
2025-09-20 23:24:29 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas1/ss104_labeled.csv
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1153，校正前pad范围: [0, 1152]，校正后范围: [0, 1152]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1392], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1153
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1153
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1153]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1153, 256])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1392], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 624], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:29 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1153，校正前pad范围: [0, 1152]，校正后范围: [0, 1152]
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1392], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1153
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1153
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1153]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1153, 256])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2784，校正前最大索引=2783, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3739]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3739, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2784，校正前最大索引=2783, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3739
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3739]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3739, 128])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5568，校正前最大索引=5567, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8465
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8465
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8465]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8465, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2496], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:29 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5568，校正前最大索引=5567, 最小索引=0
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8465
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8465
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8465]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8465, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4992], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11136]), 最大索引: 6144, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11136, 64])
2025-09-20 23:24:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4992], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 23:24:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 23:24:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11136
2025-09-20 23:24:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11136]), 最大索引: 6144, 最小索引: 0
2025-09-20 23:24:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11136, 64])
2025-09-20 23:24:29 - wind_shear:161 - DEBUG - [补点] ss104_labeled.csv | 点数2050→2304（384的倍数）
2025-09-20 23:24:29 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:29 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 23:24:29 - misc:366 - INFO -    各样本点数：[5376, 2304]（均为384的倍数）
2025-09-20 23:24:29 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 23:24:29 - misc:368 - INFO -    Offset：[0, 5376, 7680]
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:30 - wind_shear:161 - DEBUG - [补点] ee2_labeled.csv | 点数5342→5376（384的倍数）
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas1/y46_labeled.csv
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2507，校正前pad范围: [0, 2506]，校正后范围: [0, 2506]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2507
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2507
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2507]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2507, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2507，校正前pad范围: [0, 2506]，校正后范围: [0, 2506]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2507
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2507
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2507]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2507, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1011，校正前pad范围: [0, 1010]，校正后范围: [0, 1010]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1011]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1011, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1011，校正前pad范围: [0, 1010]，校正后范围: [0, 1010]
2025-09-20 23:24:30 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas1/oo124_labeled.csv
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1011]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1011, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1011，校正前pad范围: [0, 1010]，校正后范围: [0, 1010]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1011]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1011, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1011，校正前pad范围: [0, 1010]，校正后范围: [0, 1010]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1011]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1011, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1011，校正前pad范围: [0, 1010]，校正后范围: [0, 1010]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1011]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1011, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1011，校正前pad范围: [0, 1010]，校正后范围: [0, 1010]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1011]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1011, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 480], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=307，校正前pad范围: [0, 306]，校正后范围: [0, 306]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 307
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 307
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([307]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([307, 256])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 480], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=307，校正前pad范围: [0, 306]，校正后范围: [0, 306]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 307
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 307
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([307]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([307, 256])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1011，校正前pad范围: [0, 1010]，校正后范围: [0, 1010]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1011]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1011, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1011，校正前pad范围: [0, 1010]，校正后范围: [0, 1010]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1011
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1011]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1011, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2507，校正前pad范围: [0, 2506]，校正后范围: [0, 2506]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2507
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2507
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2507]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2507, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2507，校正前pad范围: [0, 2506]，校正后范围: [0, 2506]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2507
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2507
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2507]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2507, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 23:24:30 - wind_shear:161 - DEBUG - [补点] y46_labeled.csv | 点数3991→4224（384的倍数）
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:30 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas1/n108_labeled.csv
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6966
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6966
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6966]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6966, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6966
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6966
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6966]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6966, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 23:24:30 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas1/b88_labeled.csv
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2859]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2859, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2859]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2859, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - wind_shear:161 - DEBUG - [补点] oo124_labeled.csv | 点数3923→4224（384的倍数）
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 23:24:30 - misc:366 - INFO -    各样本点数：[5376, 4224]（均为384的倍数）
2025-09-20 23:24:30 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 23:24:30 - misc:368 - INFO -    Offset：[0, 5376, 9600]
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2859]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2859, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2859]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2859, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2859]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2859, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2859]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2859, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=869，校正前pad范围: [0, 868]，校正后范围: [0, 868]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 869
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 869
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([869]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([869, 256])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=869，校正前pad范围: [0, 868]，校正后范围: [0, 868]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 869
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 869
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([869]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([869, 256])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2859]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2859, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2859
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2859]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2859, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6966
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6966
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6966]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6966, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6966
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6966
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6966]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6966, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - wind_shear:161 - DEBUG - [补点] n108_labeled.csv | 点数2448→2688（384的倍数）
2025-09-20 23:24:30 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:30 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6912
2025-09-20 23:24:30 - misc:366 - INFO -    各样本点数：[4224, 2688]（均为384的倍数）
2025-09-20 23:24:30 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6912, 3])，feat=torch.Size([6912, 9])，label=torch.Size([6912])
2025-09-20 23:24:30 - misc:368 - INFO -    Offset：[0, 4224, 6912]
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=1344
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4608]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4608, 32])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=1344
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4608]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4608, 32])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1344], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 23:24:30 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas1/hhhh (121)_labeled.csv
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1557，校正前pad范围: [0, 1556]，校正后范围: [0, 1556]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 23:24:30 - wind_shear:161 - DEBUG - [补点] b88_labeled.csv | 点数4639→4992（384的倍数）
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1557
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1557
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1557]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1557, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1344], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1557，校正前pad范围: [0, 1556]，校正后范围: [0, 1556]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1557
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1557
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1557]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1557, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 672], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=539，校正前pad范围: [0, 538]，校正后范围: [0, 538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([539]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 672], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=539，校正前pad范围: [0, 538]，校正后范围: [0, 538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas1/kk163_labeled.csv
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([539]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 672], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=539，校正前pad范围: [0, 538]，校正后范围: [0, 538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([539]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 672], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=539，校正前pad范围: [0, 538]，校正后范围: [0, 538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([539]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 672], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=539，校正前pad范围: [0, 538]，校正后范围: [0, 538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([539]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 672], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=539，校正前pad范围: [0, 538]，校正后范围: [0, 538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([539]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 576], device='cuda:0')
2025-09-20 23:24:30 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 576]
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 336], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 23:24:30 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 576]
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=576, unpad长度将设为=576
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=166，校正前pad范围: [0, 165]，校正后范围: [0, 165]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 576], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(336, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数336，K=21
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 166
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 166
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([166]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([166, 256])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 576], device='cuda:0')
2025-09-20 23:24:30 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 576]
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 336], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=166，校正前pad范围: [0, 165]，校正后范围: [0, 165]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 576], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(336, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数336，K=21
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 166
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 166
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([166]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([166, 256])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 672], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=539，校正前pad范围: [0, 538]，校正后范围: [0, 538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([539]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 672], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=539，校正前pad范围: [0, 538]，校正后范围: [0, 538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1152], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([539]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1344], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1557，校正前pad范围: [0, 1556]，校正后范围: [0, 1556]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1557
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1557
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1557]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1557, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1344], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1557，校正前pad范围: [0, 1556]，校正后范围: [0, 1556]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2304], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1557
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1557
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1557]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1557, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4608]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4608, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4608], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 4608
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4608]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4608, 64])
2025-09-20 23:24:30 - wind_shear:161 - DEBUG - [补点] hhhh (121)_labeled.csv | 点数3465→3840（384的倍数）
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 5760], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=10752, unpad长度将设为=10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas2/z48_labeled.csv
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 32])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 5760], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:30 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas1/n30_labeled.csv
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 32])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2880], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5376, unpad长度将设为=5376
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5376，校正前最大索引=5375, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8234
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8234
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8234]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8234, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2880], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5376，校正前最大索引=5375, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8234
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8234
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8234]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8234, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2688, unpad长度将设为=2688
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3531]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3531, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3531]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3531, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3531]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3531, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3531]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3531, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3531]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3531, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3531]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3531, 128])
2025-09-20 23:24:30 - wind_shear:161 - DEBUG - [补点] kk163_labeled.csv | 点数4586→4608（384的倍数）
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:30 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 23:24:30 - misc:366 - INFO -    各样本点数：[4992, 4608]（均为384的倍数）
2025-09-20 23:24:30 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 23:24:30 - misc:368 - INFO -    Offset：[0, 4992, 9600]
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1344], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 720], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1344, unpad长度将设为=1344
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1078，校正前pad范围: [0, 1077]，校正后范围: [0, 1077]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1344], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1078
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1078
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1078]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1078, 256])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1344], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 720], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1078，校正前pad范围: [0, 1077]，校正后范围: [0, 1077]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1344], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1078
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1078
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1078]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1078, 256])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3531]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3531, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3531
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3531]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3531, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2880], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5376，校正前最大索引=5375, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8234
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8234
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8234]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8234, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2880], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5376，校正前最大索引=5375, 最小索引=0
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8234
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8234
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8234]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8234, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 5760], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 5760], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 64])
2025-09-20 23:24:30 - wind_shear:161 - DEBUG - [补点] n30_labeled.csv | 点数3586→3840（384的倍数）
2025-09-20 23:24:30 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas4/v44_labeled.csv
2025-09-20 23:24:30 - wind_shear:161 - DEBUG - [补点] z48_labeled.csv | 点数3898→4224（384的倍数）
2025-09-20 23:24:30 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:30 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 23:24:30 - misc:366 - INFO -    各样本点数：[3840, 4224]（均为384的倍数）
2025-09-20 23:24:30 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 23:24:30 - misc:368 - INFO -    Offset：[0, 3840, 8064]
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3578，校正前pad范围: [0, 3577]，校正后范围: [0, 3577]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas2/p102_labeled.csv
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3578
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3578
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3578]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3578, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3578，校正前pad范围: [0, 3577]，校正后范围: [0, 3577]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3578
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3578
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3578]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3578, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1539，校正前pad范围: [0, 1538]，校正后范围: [0, 1538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1539]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1539，校正前pad范围: [0, 1538]，校正后范围: [0, 1538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1539]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1539，校正前pad范围: [0, 1538]，校正后范围: [0, 1538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1539]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1539，校正前pad范围: [0, 1538]，校正后范围: [0, 1538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1539]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1539，校正前pad范围: [0, 1538]，校正后范围: [0, 1538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1539]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1539，校正前pad范围: [0, 1538]，校正后范围: [0, 1538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1539]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=485，校正前pad范围: [0, 484]，校正后范围: [0, 484]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 485
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 485
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([485]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([485, 256])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=485，校正前pad范围: [0, 484]，校正后范围: [0, 484]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 485
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 485
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([485]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([485, 256])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1539，校正前pad范围: [0, 1538]，校正后范围: [0, 1538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1539]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1539，校正前pad范围: [0, 1538]，校正后范围: [0, 1538]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1539
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1539]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1539, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3578，校正前pad范围: [0, 3577]，校正后范围: [0, 3577]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3578
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3578
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3578]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3578, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3578，校正前pad范围: [0, 3577]，校正后范围: [0, 3577]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3578
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3578
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3578]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3578, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 23:24:30 - wind_shear:161 - DEBUG - [补点] p102_labeled.csv | 点数3019→3072（384的倍数）
2025-09-20 23:24:30 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas3/period107_labeled.csv
2025-09-20 23:24:30 - wind_shear:161 - DEBUG - [补点] v44_labeled.csv | 点数4409→4608（384的倍数）
2025-09-20 23:24:30 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:30 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 23:24:30 - misc:366 - INFO -    各样本点数：[3840, 4608]（均为384的倍数）
2025-09-20 23:24:30 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 23:24:30 - misc:368 - INFO -    Offset：[0, 3840, 8448]
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2864，校正前pad范围: [0, 2863]，校正后范围: [0, 2863]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2864
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2864
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2864]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2864, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2864，校正前pad范围: [0, 2863]，校正后范围: [0, 2863]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2864
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2864
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2864]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2864, 64])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1132，校正前pad范围: [0, 1131]，校正后范围: [0, 1131]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1132
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1132
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1132]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1132, 128])
2025-09-20 23:24:30 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn133_labeled.csv
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1132，校正前pad范围: [0, 1131]，校正后范围: [0, 1131]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1132
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1132
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1132]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1132, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1132，校正前pad范围: [0, 1131]，校正后范围: [0, 1131]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1132
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1132
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1132]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1132, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1132，校正前pad范围: [0, 1131]，校正后范围: [0, 1131]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1132
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1132
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1132]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1132, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:30 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1132，校正前pad范围: [0, 1131]，校正后范围: [0, 1131]
2025-09-20 23:24:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1132
2025-09-20 23:24:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1132
2025-09-20 23:24:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1132]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1132, 128])
2025-09-20 23:24:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1132，校正前pad范围: [0, 1131]，校正后范围: [0, 1131]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1132
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1132
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1132]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1132, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 480], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=361，校正前pad范围: [0, 360]，校正后范围: [0, 360]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 361
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 361
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([361]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([361, 256])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 480], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=361，校正前pad范围: [0, 360]，校正后范围: [0, 360]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 361
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 361
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([361]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([361, 256])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1132，校正前pad范围: [0, 1131]，校正后范围: [0, 1131]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1132
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1132
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1132]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1132, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1132，校正前pad范围: [0, 1131]，校正后范围: [0, 1131]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1132
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1132
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1132]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1132, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2864，校正前pad范围: [0, 2863]，校正后范围: [0, 2863]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2864
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2864
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2864]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2864, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2864，校正前pad范围: [0, 2863]，校正后范围: [0, 2863]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2864
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2864
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2864]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2864, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:31 - wind_shear:161 - DEBUG - [补点] period107_labeled.csv | 点数4268→4608（384的倍数）
2025-09-20 23:24:31 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:31 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 23:24:31 - misc:366 - INFO -    各样本点数：[3072, 4608]（均为384的倍数）
2025-09-20 23:24:31 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 23:24:31 - misc:368 - INFO -    Offset：[0, 3072, 7680]
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 7680], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 2304], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 7680], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=1152
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 7680], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 2304], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 7680], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=1152
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 3840], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1152], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 23:24:31 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas1/m2_labeled.csv
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 3840], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5494
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5494
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5494]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5494, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 3840], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1152], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 3840], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5494
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5494
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5494]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5494, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  576], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2211]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2211, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  576], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2211]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2211, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  576], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2211]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2211, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  576], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2211]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2211, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - wind_shear:161 - DEBUG - [补点] nn133_labeled.csv | 点数4911→4992（384的倍数）
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  576], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2211]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2211, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  576], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2211]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2211, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 672, 960], device='cuda:0')
2025-09-20 23:24:31 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为288（小于384），offset=[0, 672, 960]
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 288], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 23:24:31 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为288（小于384），offset=[0, 672, 960]
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=660，校正前pad范围: [0, 659]，校正后范围: [0, 659]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 672, 960], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(288, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数288，K=18
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 660
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 660
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([660]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([660, 256])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 672, 960], device='cuda:0')
2025-09-20 23:24:31 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为288（小于384），offset=[0, 672, 960]
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 288], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=660，校正前pad范围: [0, 659]，校正后范围: [0, 659]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 672, 960], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(288, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数288，K=18
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 660
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 660
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([660]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([660, 256])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  576], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2211]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2211, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  576], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 1920], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2211
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2211]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2211, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 3840], device='cuda:0')
2025-09-20 23:24:31 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas2/d131_labeled.csv
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1152], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 3840], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5494
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5494
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5494]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5494, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 3840], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1152], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 3840], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5494
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5494
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5494]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5494, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 7680], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 2304], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 7680], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 7680], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 2304], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 7680], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:31 - wind_shear:161 - DEBUG - [补点] m2_labeled.csv | 点数3477→3840（384的倍数）
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 23:24:31 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas1/g18_labeled.csv
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7199
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7199
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7199]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7199, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7199
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7199
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7199]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7199, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas2/iiii (73)_labeled.csv
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2998]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2998, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2998]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2998, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2998]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2998, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2998]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2998, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2998]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2998, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2998]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2998, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 528], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=913，校正前pad范围: [0, 912]，校正后范围: [0, 912]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 913
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 913
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([913]), 最大索引: 672, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([913, 256])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 528], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=913，校正前pad范围: [0, 912]，校正后范围: [0, 912]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 913
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 913
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([913]), 最大索引: 672, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([913, 256])
2025-09-20 23:24:31 - wind_shear:161 - DEBUG - [补点] d131_labeled.csv | 点数4699→4992（384的倍数）
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:31 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 23:24:31 - misc:366 - INFO -    各样本点数：[4992, 4992]（均为384的倍数）
2025-09-20 23:24:31 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 23:24:31 - misc:368 - INFO -    Offset：[0, 4992, 9984]
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2998]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2998, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2998
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2998]), 最大索引: 1344, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2998, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7199
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7199
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7199]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7199, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7199
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7199
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7199]), 最大索引: 2688, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7199, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 23:24:31 - wind_shear:161 - DEBUG - [补点] g18_labeled.csv | 点数3889→4224（384的倍数）
2025-09-20 23:24:31 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:31 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 23:24:31 - misc:366 - INFO -    各样本点数：[3840, 4224]（均为384的倍数）
2025-09-20 23:24:31 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 23:24:31 - misc:368 - INFO -    Offset：[0, 3840, 8064]
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2688], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6912, unpad长度将设为=6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=1344
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2688], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=1344
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 23:24:31 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas1/ss2_labeled.csv
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1344], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3456, unpad长度将设为=3456
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2659，校正前pad范围: [0, 2658]，校正后范围: [0, 2658]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - wind_shear:161 - DEBUG - [补点] iiii (73)_labeled.csv | 点数4499→4608（384的倍数）
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2659
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2659
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2659]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2659, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1344], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2659，校正前pad范围: [0, 2658]，校正后范围: [0, 2658]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2659
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2659
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2659]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2659, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1728, unpad长度将设为=1728
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1030，校正前pad范围: [0, 1029]，校正后范围: [0, 1029]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1030，校正前pad范围: [0, 1029]，校正后范围: [0, 1029]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas2/bb17_labeled.csv
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1030，校正前pad范围: [0, 1029]，校正后范围: [0, 1029]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1030，校正前pad范围: [0, 1029]，校正后范围: [0, 1029]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1030，校正前pad范围: [0, 1029]，校正后范围: [0, 1029]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1030，校正前pad范围: [0, 1029]，校正后范围: [0, 1029]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 864], device='cuda:0')
2025-09-20 23:24:31 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 528, 864]
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 336], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 23:24:31 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 528, 864]
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=864, unpad长度将设为=864
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=326，校正前pad范围: [0, 325]，校正后范围: [0, 325]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 864], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(336, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数336，K=21
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 326
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 326
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([326]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([326, 256])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - wind_shear:161 - DEBUG - [补点] ss2_labeled.csv | 点数1596→1920（384的倍数）
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 864], device='cuda:0')
2025-09-20 23:24:31 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 528, 864]
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 336], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=326，校正前pad范围: [0, 325]，校正后范围: [0, 325]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 864], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(336, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数336，K=21
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 326
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 326
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([326]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([326, 256])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1030，校正前pad范围: [0, 1029]，校正后范围: [0, 1029]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1030，校正前pad范围: [0, 1029]，校正后范围: [0, 1029]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1344], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2659，校正前pad范围: [0, 2658]，校正后范围: [0, 2658]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2659
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2659
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2659]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2659, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1344], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2659，校正前pad范围: [0, 2658]，校正后范围: [0, 2658]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2659
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2659
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2659]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2659, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2688], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 23:24:31 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas3/u96_labeled.csv
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2688], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7081
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7081
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7081]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7081, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7081
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7081
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7081]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7081, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2884
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2884
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2884]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2884, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2884
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2884
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn192_labeled.csv
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2884]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2884, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2884
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2884
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2884]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2884, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - wind_shear:161 - DEBUG - [补点] bb17_labeled.csv | 点数4780→4992（384的倍数）
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2884
2025-09-20 23:24:31 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2884
2025-09-20 23:24:31 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - misc:366 - INFO -    各样本点数：[4608, 4992]（均为384的倍数）
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 23:24:31 - misc:368 - INFO -    Offset：[0, 4608, 9600]
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2884]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2884, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2884
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2884
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2884]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2884, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2884
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2884
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2884]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2884, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=871，校正前pad范围: [0, 870]，校正后范围: [0, 870]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 871
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 871
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([871]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([871, 256])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=871，校正前pad范围: [0, 870]，校正后范围: [0, 870]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 871
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 871
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([871]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([871, 256])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - wind_shear:161 - DEBUG - [补点] u96_labeled.csv | 点数2970→3072（384的倍数）
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:31 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:31 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=4992
2025-09-20 23:24:31 - misc:366 - INFO -    各样本点数：[1920, 3072]（均为384的倍数）
2025-09-20 23:24:31 - misc:367 - INFO -    拼接后维度：coord=torch.Size([4992, 3])，feat=torch.Size([4992, 9])，label=torch.Size([4992])
2025-09-20 23:24:31 - misc:368 - INFO -    Offset：[0, 1920, 4992]
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2884
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2884
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2884]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2884, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2884
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2884
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2884]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2884, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7081
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7081
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7081]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7081, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7081
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7081
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7081]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7081, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas1/g118_labeled.csv
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5417
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5417
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5417]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5417, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5417
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5417
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5417]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5417, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2077]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - wind_shear:161 - DEBUG - [补点] nn192_labeled.csv | 点数4787→4992（384的倍数）
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2077, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2077]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2077, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2077]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2077, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2077]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2077, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2077]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2077, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2077]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2077, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 528], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 23:24:31 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas2/a14_labeled.csv
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=605，校正前pad范围: [0, 604]，校正后范围: [0, 604]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 605
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 605
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([605]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([605, 256])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 528], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:31 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=605，校正前pad范围: [0, 604]，校正后范围: [0, 604]
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 605
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 605
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([605]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([605, 256])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2077]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2077, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2077
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2077]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2077, 128])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5417
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5417
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5417]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5417, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:31 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5417
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5417
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5417]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5417, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:32 - wind_shear:161 - DEBUG - [补点] g118_labeled.csv | 点数4206→4224（384的倍数）
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 23:24:32 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas1/c211_labeled.csv
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6056
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6056
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6056]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6056, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6056
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6056
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6056]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6056, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas3/ii14_labeled.csv
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - wind_shear:161 - DEBUG - [补点] a14_labeled.csv | 点数4024→4224（384的倍数）
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:32 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 23:24:32 - misc:366 - INFO -    各样本点数：[4992, 4224]（均为384的倍数）
2025-09-20 23:24:32 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 23:24:32 - misc:368 - INFO -    Offset：[0, 4992, 9216]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2400]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2400, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2400]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2400, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2400]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2400, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2400]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2400, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2400]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2400, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2400]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2400, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 576], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=707，校正前pad范围: [0, 706]，校正后范围: [0, 706]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 707
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 707
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([707]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([707, 256])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 576], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=707，校正前pad范围: [0, 706]，校正后范围: [0, 706]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 707
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 707
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([707]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([707, 256])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2400]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2400, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2400]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2400, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6056
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6056
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6056]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6056, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6056
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6056
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6056]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6056, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 23:24:32 - wind_shear:161 - DEBUG - [补点] ii14_labeled.csv | 点数2809→3072（384的倍数）
2025-09-20 23:24:32 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:32 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 23:24:32 - misc:366 - INFO -    各样本点数：[4224, 3072]（均为384的倍数）
2025-09-20 23:24:32 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 23:24:32 - misc:368 - INFO -    Offset：[0, 4224, 7296]
2025-09-20 23:24:32 - wind_shear:161 - DEBUG - [补点] c211_labeled.csv | 点数3361→3456（384的倍数）
2025-09-20 23:24:32 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas1/b42_labeled.csv
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4608], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4608], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2304], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5190
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5190
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5190]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5190, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2304], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5190
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5190
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5190]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5190, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1936]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1936, 128])
2025-09-20 23:24:32 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas3/ii8_labeled.csv
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1936]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1936, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1936]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1936, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1936]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1936, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1936]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1936, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1936]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1936, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 576], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=565，校正前pad范围: [0, 564]，校正后范围: [0, 564]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 565
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 565
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([565]), 最大索引: 384, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([565, 256])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 576], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=565，校正前pad范围: [0, 564]，校正后范围: [0, 564]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 565
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 565
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([565]), 最大索引: 384, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([565, 256])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1936]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1936, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1936
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1936]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1936, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2304], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5190
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5190
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5190]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5190, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2304], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5190
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5190
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5190]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5190, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4608], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4608], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:32 - wind_shear:161 - DEBUG - [补点] b42_labeled.csv | 点数4233→4608（384的倍数）
2025-09-20 23:24:32 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:32 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 23:24:32 - misc:366 - INFO -    各样本点数：[3456, 4608]（均为384的倍数）
2025-09-20 23:24:32 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 23:24:32 - misc:368 - INFO -    Offset：[0, 3456, 8064]
2025-09-20 23:24:32 - wind_shear:161 - DEBUG - [补点] ii8_labeled.csv | 点数2708→3072（384的倍数）
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:32 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas3/gh1 (96)_labeled.csv
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 23:24:32 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas1/aa77_labeled.csv
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4449，校正前pad范围: [0, 4448]，校正后范围: [0, 4448]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4449
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4449
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4449]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4449, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4449，校正前pad范围: [0, 4448]，校正后范围: [0, 4448]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4449
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4449
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4449]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4449, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1855，校正前pad范围: [0, 1854]，校正后范围: [0, 1854]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1855]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1855, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1855，校正前pad范围: [0, 1854]，校正后范围: [0, 1854]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1855]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1855, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1855，校正前pad范围: [0, 1854]，校正后范围: [0, 1854]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1855]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1855, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1855，校正前pad范围: [0, 1854]，校正后范围: [0, 1854]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1855]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1855, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1855，校正前pad范围: [0, 1854]，校正后范围: [0, 1854]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1855]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1855, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1855，校正前pad范围: [0, 1854]，校正后范围: [0, 1854]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1855]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1855, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=585，校正前pad范围: [0, 584]，校正后范围: [0, 584]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 585
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 585
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([585]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([585, 256])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=585，校正前pad范围: [0, 584]，校正后范围: [0, 584]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 585
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 585
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([585]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([585, 256])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1855，校正前pad范围: [0, 1854]，校正后范围: [0, 1854]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1855]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1855, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1855，校正前pad范围: [0, 1854]，校正后范围: [0, 1854]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1855
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1855]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1855, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4449，校正前pad范围: [0, 4448]，校正后范围: [0, 4448]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4449
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4449
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4449]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4449, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4449，校正前pad范围: [0, 4448]，校正后范围: [0, 4448]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4449
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4449
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4449]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4449, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 23:24:32 - wind_shear:161 - DEBUG - [补点] aa77_labeled.csv | 点数3715→3840（384的倍数）
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 23:24:32 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas2/iiii (149)_labeled.csv
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 23:24:32 - wind_shear:161 - DEBUG - [补点] gh1 (96)_labeled.csv | 点数4511→4608（384的倍数）
2025-09-20 23:24:32 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas3/qq10_labeled.csv
2025-09-20 23:24:32 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:32 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 23:24:32 - misc:366 - INFO -    各样本点数：[3072, 4608]（均为384的倍数）
2025-09-20 23:24:32 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 23:24:32 - misc:368 - INFO -    Offset：[0, 3072, 7680]
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5421
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5421
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5421]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5421, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5421
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5421
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5421]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5421, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2031]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2031, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2031]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2031, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2031]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2031, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2031]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2031, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2031]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2031, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2031]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2031, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 528], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=607，校正前pad范围: [0, 606]，校正后范围: [0, 606]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 607
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 607
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([607]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([607, 256])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 528], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=607，校正前pad范围: [0, 606]，校正后范围: [0, 606]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 607
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 607
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([607]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([607, 256])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2031]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2031, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2031
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2031]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2031, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5421
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5421
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5421]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5421, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:32 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5421
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5421
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5421]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5421, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:32 - wind_shear:161 - DEBUG - [补点] iiii (149)_labeled.csv | 点数4623→4992（384的倍数）
2025-09-20 23:24:32 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:32 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 23:24:32 - misc:366 - INFO -    各样本点数：[3840, 4992]（均为384的倍数）
2025-09-20 23:24:32 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 23:24:32 - misc:368 - INFO -    Offset：[0, 3840, 8832]
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - wind_shear:161 - DEBUG - [补点] qq10_labeled.csv | 点数4847→4992（384的倍数）
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4244，校正前pad范围: [0, 4243]，校正后范围: [0, 4243]
2025-09-20 23:24:32 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas2/d85_labeled.csv
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4244
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4244
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4244]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4244, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4244，校正前pad范围: [0, 4243]，校正后范围: [0, 4243]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4244
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4244
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4244]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4244, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1768，校正前pad范围: [0, 1767]，校正后范围: [0, 1767]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1768]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230316/datas1/ee86_labeled.csv
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1768, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1768，校正前pad范围: [0, 1767]，校正后范围: [0, 1767]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1768]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1768, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1768，校正前pad范围: [0, 1767]，校正后范围: [0, 1767]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1768]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1768, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1768，校正前pad范围: [0, 1767]，校正后范围: [0, 1767]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1768]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1768, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1768，校正前pad范围: [0, 1767]，校正后范围: [0, 1767]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1768]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1768, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1768，校正前pad范围: [0, 1767]，校正后范围: [0, 1767]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1768]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1768, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 624], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=552，校正前pad范围: [0, 551]，校正后范围: [0, 551]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 552
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 552
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([552]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([552, 256])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 624], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=552，校正前pad范围: [0, 551]，校正后范围: [0, 551]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 552
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 552
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([552]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([552, 256])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1768，校正前pad范围: [0, 1767]，校正后范围: [0, 1767]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1768]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1768, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1768，校正前pad范围: [0, 1767]，校正后范围: [0, 1767]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1768
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1768]), 最大索引: 1152, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1768, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4244，校正前pad范围: [0, 4243]，校正后范围: [0, 4243]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4244
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4244
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4244]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4244, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4244，校正前pad范围: [0, 4243]，校正后范围: [0, 4243]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4244
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4244
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4244]), 最大索引: 2304, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4244, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 23:24:32 - wind_shear:161 - DEBUG - [补点] d85_labeled.csv | 点数3813→3840（384的倍数）
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3072], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4992
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4992
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 4992
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 4992
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4992]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4992, 32])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4992], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3072], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4992], device='cuda:0')
2025-09-20 23:24:32 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas1/hhhh (36)_labeled.csv
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4992
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4992
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 4992
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 4992
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4992]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4992, 32])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas1/m171_labeled.csv
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1536], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1870，校正前pad范围: [0, 1869]，校正后范围: [0, 1869]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1870
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1870
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1870]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1870, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1536], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1870，校正前pad范围: [0, 1869]，校正后范围: [0, 1869]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2496], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1870
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1870
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1870]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1870, 64])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 768], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=655，校正前pad范围: [0, 654]，校正后范围: [0, 654]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 655
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 655
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([655]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([655, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 768], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=655，校正前pad范围: [0, 654]，校正后范围: [0, 654]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 655
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 655
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([655]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([655, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 768], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=655，校正前pad范围: [0, 654]，校正后范围: [0, 654]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 655
2025-09-20 23:24:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 655
2025-09-20 23:24:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([655]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([655, 128])
2025-09-20 23:24:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 768], device='cuda:0')
2025-09-20 23:24:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:32 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=655，校正前pad范围: [0, 654]，校正后范围: [0, 654]
2025-09-20 23:24:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 655
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 655
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([655]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([655, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 768], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=655，校正前pad范围: [0, 654]，校正后范围: [0, 654]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 655
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 655
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([655]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([655, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 768], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=655，校正前pad范围: [0, 654]，校正后范围: [0, 654]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 655
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 655
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([655]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([655, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 624], device='cuda:0')
2025-09-20 23:24:33 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 624]
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 384], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 23:24:33 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 624]
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=624, unpad长度将设为=624
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=203，校正前pad范围: [0, 202]，校正后范围: [0, 202]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 624], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 203
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 203
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([203]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([203, 256])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 624], device='cuda:0')
2025-09-20 23:24:33 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 624]
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 384], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=203，校正前pad范围: [0, 202]，校正后范围: [0, 202]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 624], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 203
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 203
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([203]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([203, 256])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 768], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:33 - wind_shear:161 - DEBUG - [补点] ee86_labeled.csv | 点数5612→5760（384的倍数）
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=655，校正前pad范围: [0, 654]，校正后范围: [0, 654]
2025-09-20 23:24:33 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:33 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=10752
2025-09-20 23:24:33 - misc:366 - INFO -    各样本点数：[4992, 5760]（均为384的倍数）
2025-09-20 23:24:33 - misc:367 - INFO -    拼接后维度：coord=torch.Size([10752, 3])，feat=torch.Size([10752, 9])，label=torch.Size([10752])
2025-09-20 23:24:33 - misc:368 - INFO -    Offset：[0, 4992, 10752]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 655
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 655
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([655]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([655, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 768], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=655，校正前pad范围: [0, 654]，校正后范围: [0, 654]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 655
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 655
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([655]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([655, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2496], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1536], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1870，校正前pad范围: [0, 1869]，校正后范围: [0, 1869]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2496], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1870
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1870
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1870]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1870, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2496], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1536], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1870，校正前pad范围: [0, 1869]，校正后范围: [0, 1869]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2496], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1870
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1870
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1870]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1870, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4992], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3072], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4992], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4992
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4992
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 4992
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 4992
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4992]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4992, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4992], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3072], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4992], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4992
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4992
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 4992
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 4992
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4992]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4992, 64])
2025-09-20 23:24:33 - wind_shear:161 - DEBUG - [补点] m171_labeled.csv | 点数3284→3456（384的倍数）
2025-09-20 23:24:33 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:33 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 23:24:33 - misc:366 - INFO -    各样本点数：[3840, 3456]（均为384的倍数）
2025-09-20 23:24:33 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 23:24:33 - misc:368 - INFO -    Offset：[0, 3840, 7296]
2025-09-20 23:24:33 - wind_shear:161 - DEBUG - [补点] hhhh (36)_labeled.csv | 点数3393→3456（384的倍数）
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas2/ll167_labeled.csv
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas2/ll63_labeled.csv
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6779
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6779
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6779]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6779, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6779
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6779
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6779]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6779, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2740]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2740, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2740]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2740, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2740]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2740, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2740]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2740, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2740]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2740, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2740]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2740, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 528], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=827，校正前pad范围: [0, 826]，校正后范围: [0, 826]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 827
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 827
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([827]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([827, 256])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 528], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=827，校正前pad范围: [0, 826]，校正后范围: [0, 826]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 827
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 827
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([827]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([827, 256])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2740]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2740, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2740
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2740]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2740, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6779
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6779
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6779]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6779, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6779
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6779
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6779]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6779, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 23:24:33 - wind_shear:161 - DEBUG - [补点] ll167_labeled.csv | 点数5424→5760（384的倍数）
2025-09-20 23:24:33 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:33 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 23:24:33 - misc:366 - INFO -    各样本点数：[3456, 5760]（均为384的倍数）
2025-09-20 23:24:33 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 23:24:33 - misc:368 - INFO -    Offset：[0, 3456, 9216]
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5241
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5241
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5241]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5241, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5241
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5241
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5241]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5241, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:33 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas1/eeee (194)_labeled.csv
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2012]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2012, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2012]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2012, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2012]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2012, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - wind_shear:161 - DEBUG - [补点] ll63_labeled.csv | 点数5925→6144（384的倍数）
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2012]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2012, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2012]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2012, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2012]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2012, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 23:24:33 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas2/bb54_labeled.csv
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 384], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=583，校正前pad范围: [0, 582]，校正后范围: [0, 582]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 583
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 583
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([583]), 最大索引: 528, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([583, 256])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 384], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=583，校正前pad范围: [0, 582]，校正后范围: [0, 582]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 583
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 583
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([583]), 最大索引: 528, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([583, 256])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2012]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2012, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2012
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2012]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2012, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5241
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5241
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5241]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5241, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5241
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5241
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5241]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5241, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 23:24:33 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas3/u51_labeled.csv
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 23:24:33 - wind_shear:161 - DEBUG - [补点] eeee (194)_labeled.csv | 点数3926→4224（384的倍数）
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5638
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5638
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5638]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5638, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5638
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5638
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5638]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5638, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2177]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2177, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2177]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2177, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2177]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2177, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2177]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2177, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2177]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2177, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas1/kk202_labeled.csv
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2177]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2177, 128])
2025-09-20 23:24:33 - wind_shear:161 - DEBUG - [补点] bb54_labeled.csv | 点数4290→4608（384的倍数）
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:33 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=10752
2025-09-20 23:24:33 - misc:366 - INFO -    各样本点数：[6144, 4608]（均为384的倍数）
2025-09-20 23:24:33 - misc:367 - INFO -    拼接后维度：coord=torch.Size([10752, 3])，feat=torch.Size([10752, 9])，label=torch.Size([10752])
2025-09-20 23:24:33 - misc:368 - INFO -    Offset：[0, 6144, 10752]
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  432, 1008], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 576], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=648，校正前pad范围: [0, 647]，校正后范围: [0, 647]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  432, 1008], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 648
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 648
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([648]), 最大索引: 432, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([648, 256])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  432, 1008], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 576], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=648，校正前pad范围: [0, 647]，校正后范围: [0, 647]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  432, 1008], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 648
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 648
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([648]), 最大索引: 432, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([648, 256])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2177]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2177, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2177
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2177]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2177, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5638
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5638
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5638]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5638, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5638
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5638
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5638]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5638, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 23:24:33 - wind_shear:161 - DEBUG - [补点] u51_labeled.csv | 点数3454→3456（384的倍数）
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas1/w170_labeled.csv
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas1/eeee (126)_labeled.csv
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5446
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5446
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5446]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5446, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5446
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5446
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5446]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5446, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2102]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2102, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2102]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2102, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2102]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2102, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - wind_shear:161 - DEBUG - [补点] kk202_labeled.csv | 点数4442→4608（384的倍数）
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:33 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 23:24:33 - misc:366 - INFO -    各样本点数：[4224, 4608]（均为384的倍数）
2025-09-20 23:24:33 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 23:24:33 - misc:368 - INFO -    Offset：[0, 4224, 8832]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2102]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2102, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2102]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2102, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2102]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2102, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 576], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=612，校正前pad范围: [0, 611]，校正后范围: [0, 611]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 612
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 612
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([612]), 最大索引: 384, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([612, 256])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 576], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=612，校正前pad范围: [0, 611]，校正后范围: [0, 611]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 612
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 612
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([612]), 最大索引: 384, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([612, 256])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2102]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2102, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2102
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2102]), 最大索引: 768, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2102, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5446
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5446
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5446]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5446, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2304], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5446
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5446
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5446]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5446, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4608], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 23:24:33 - wind_shear:161 - DEBUG - [补点] w170_labeled.csv | 点数3819→3840（384的倍数）
2025-09-20 23:24:33 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:33 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 23:24:33 - misc:366 - INFO -    各样本点数：[3456, 3840]（均为384的倍数）
2025-09-20 23:24:33 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 23:24:33 - misc:368 - INFO -    Offset：[0, 3456, 7296]
2025-09-20 23:24:33 - wind_shear:161 - DEBUG - [补点] eeee (126)_labeled.csv | 点数3238→3456（384的倍数）
2025-09-20 23:24:33 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (211)_labeled.csv
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6337
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6337
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6337]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas1/b158_labeled.csv
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6337, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6337
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6337
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6337]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6337, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2500]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2500, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2500]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2500, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2500]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2500, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2500]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2500, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2500]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2500, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2500]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2500, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 624], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=728，校正前pad范围: [0, 727]，校正后范围: [0, 727]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 728
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 728
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([728]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([728, 256])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 624], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 23:24:33 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=728，校正前pad范围: [0, 727]，校正后范围: [0, 727]
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 728
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 728
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([728]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([728, 256])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2500]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2500, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2500
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2500]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2500, 128])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6337
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6337
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6337]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6337, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 23:24:33 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6337
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6337
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6337]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6337, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 23:24:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 23:24:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 23:24:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 23:24:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 23:24:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 23:24:33 - wind_shear:161 - DEBUG - [补点] gggg (211)_labeled.csv | 点数3448→3456（384的倍数）
2025-09-20 23:24:33 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:33 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6912
2025-09-20 23:24:33 - misc:366 - INFO -    各样本点数：[3456, 3456]（均为384的倍数）
2025-09-20 23:24:33 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6912, 3])，feat=torch.Size([6912, 9])，label=torch.Size([6912])
2025-09-20 23:24:33 - misc:368 - INFO -    Offset：[0, 3456, 6912]
2025-09-20 23:24:34 - wind_shear:161 - DEBUG - [补点] b158_labeled.csv | 点数4008→4224（384的倍数）
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 5760], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=10752, unpad长度将设为=10752
2025-09-20 23:24:34 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas2/tt16_labeled.csv
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 32])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 5760], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 32])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2880], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5376, unpad长度将设为=5376
2025-09-20 23:24:34 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas2/vv165_labeled.csv
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5376，校正前最大索引=5375, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8222
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8222
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8222]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8222, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2880], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5376，校正前最大索引=5375, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8222
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8222
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8222]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8222, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2688, unpad长度将设为=2688
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3529]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3529, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3529]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3529, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3529]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3529, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3529]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3529, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3529]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3529, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3529]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3529, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1344], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 720], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1344, unpad长度将设为=1344
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1060，校正前pad范围: [0, 1059]，校正后范围: [0, 1059]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1344], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1060
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1060
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1060]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1060, 256])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1344], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 720], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1060，校正前pad范围: [0, 1059]，校正后范围: [0, 1059]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1344], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1060
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1060
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1060]), 最大索引: 624, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1060, 256])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3529]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3529, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - wind_shear:161 - DEBUG - [补点] tt16_labeled.csv | 点数1720→1920（384的倍数）
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 23:24:34 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:34 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6144
2025-09-20 23:24:34 - misc:366 - INFO -    各样本点数：[4224, 1920]（均为384的倍数）
2025-09-20 23:24:34 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6144, 3])，feat=torch.Size([6144, 9])，label=torch.Size([6144])
2025-09-20 23:24:34 - misc:368 - INFO -    Offset：[0, 4224, 6144]
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3529
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3529]), 最大索引: 1248, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3529, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2880], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5376，校正前最大索引=5375, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8222
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8222
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8222]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8222, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2880], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5376，校正前最大索引=5375, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 5376], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8222
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8222
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8222]), 最大索引: 2496, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8222, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 5760], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 5760], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4992, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 4992, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 64])
2025-09-20 23:24:34 - wind_shear:161 - DEBUG - [补点] vv165_labeled.csv | 点数2998→3072（384的倍数）
2025-09-20 23:24:34 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn145_labeled.csv
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5142
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5142
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5142]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5142, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5142
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5142
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5142]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5142, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn73_labeled.csv
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1965]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1965, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1965]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1965, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1965]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1965, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1965]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1965, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1965]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1965, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1965]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1965, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 432], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=583，校正前pad范围: [0, 582]，校正后范围: [0, 582]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 583
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 583
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([583]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([583, 256])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 432], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=583，校正前pad范围: [0, 582]，校正后范围: [0, 582]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 583
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 583
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([583]), 最大索引: 480, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([583, 256])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1965]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1965, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1965
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1965]), 最大索引: 960, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1965, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5142
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5142
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5142]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5142, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5142
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5142
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5142]), 最大索引: 1920, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5142, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 23:24:34 - wind_shear:161 - DEBUG - [补点] nn145_labeled.csv | 点数5209→5376（384的倍数）
2025-09-20 23:24:34 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:34 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 23:24:34 - misc:366 - INFO -    各样本点数：[3072, 5376]（均为384的倍数）
2025-09-20 23:24:34 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 23:24:34 - misc:368 - INFO -    Offset：[0, 3072, 8448]
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 9216], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 5760], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 9216], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 9216], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 5760], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 9216], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas1/kk143_labeled.csv
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2880], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6842
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6842
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6842]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6842, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2880], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6842
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6842
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6842]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6842, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2863]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2863, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2863]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2863, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2863]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2863, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2863]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2863, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2863]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2863, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - wind_shear:161 - DEBUG - [补点] nn73_labeled.csv | 点数5999→6144（384的倍数）
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2863]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2863, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  432, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 720], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=859，校正前pad范围: [0, 858]，校正后范围: [0, 858]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  432, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 859
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 859
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([859]), 最大索引: 432, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([859, 256])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  432, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 720], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=859，校正前pad范围: [0, 858]，校正后范围: [0, 858]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  432, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 859
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 859
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([859]), 最大索引: 432, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([859, 256])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:34 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas1/hhhh (110)_labeled.csv
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2863]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2863, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1440], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2863
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2863]), 最大索引: 864, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2863, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2880], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6842
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6842
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6842]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6842, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2880], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 23:24:34 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6842
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6842
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6842]), 最大索引: 1728, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6842, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 9216], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 5760], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 9216], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 9216], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 5760], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 9216], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3456, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=10752, unpad长度将设为=10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 6144, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 32])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - wind_shear:161 - DEBUG - [补点] kk143_labeled.csv | 点数4013→4224（384的倍数）
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 6144, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 32])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5376], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5376, unpad长度将设为=5376
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5227，校正前pad范围: [0, 5226]，校正后范围: [0, 5226]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5376], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5227
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5227
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5227]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5227, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5376], device='cuda:0')
2025-09-20 23:24:34 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas1/mm114_labeled.csv
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5227，校正前pad范围: [0, 5226]，校正后范围: [0, 5226]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5376], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5227
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5227
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5227]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5227, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230306/datas2/f1 (152)_labeled.csv
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2688, unpad长度将设为=2688
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2342，校正前pad范围: [0, 2341]，校正后范围: [0, 2341]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2342]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2342, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - wind_shear:161 - DEBUG - [补点] hhhh (110)_labeled.csv | 点数3379→3456（384的倍数）
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1152], device='cuda:0')
2025-09-20 23:24:34 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:34 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 23:24:34 - misc:366 - INFO -    各样本点数：[6144, 3456]（均为384的倍数）
2025-09-20 23:24:34 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 23:24:34 - misc:368 - INFO -    Offset：[0, 6144, 9600]
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2342，校正前pad范围: [0, 2341]，校正后范围: [0, 2341]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2342]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2342, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2342，校正前pad范围: [0, 2341]，校正后范围: [0, 2341]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2342]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2342, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2342，校正前pad范围: [0, 2341]，校正后范围: [0, 2341]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2342]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2342, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2342，校正前pad范围: [0, 2341]，校正后范围: [0, 2341]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2342]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2342, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2342，校正前pad范围: [0, 2341]，校正后范围: [0, 2341]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2342]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2342, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1344], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 576], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1344, unpad长度将设为=1344
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=752，校正前pad范围: [0, 751]，校正后范围: [0, 751]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1344], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 752
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 752
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([752]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([752, 256])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1344], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 576], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=752，校正前pad范围: [0, 751]，校正后范围: [0, 751]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1344], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 752
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 752
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([752]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([752, 256])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2342，校正前pad范围: [0, 2341]，校正后范围: [0, 2341]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2342]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2342, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2342，校正前pad范围: [0, 2341]，校正后范围: [0, 2341]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2688], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2342
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2342]), 最大索引: 1536, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2342, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5376], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5227，校正前pad范围: [0, 5226]，校正后范围: [0, 5226]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5376], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5227
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5227
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5227]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5227, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5376], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5227，校正前pad范围: [0, 5226]，校正后范围: [0, 5226]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5376], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5227
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5227
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5227]), 最大索引: 3072, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5227, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 6144, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 10752], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 6144, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 64])
2025-09-20 23:24:34 - wind_shear:161 - DEBUG - [补点] mm114_labeled.csv | 点数3808→3840（384的倍数）
2025-09-20 23:24:34 - wind_shear:161 - DEBUG - [补点] f1 (152)_labeled.csv | 点数3433→3456（384的倍数）
2025-09-20 23:24:34 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:34 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 23:24:34 - misc:366 - INFO -    各样本点数：[4224, 3456]（均为384的倍数）
2025-09-20 23:24:34 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 23:24:34 - misc:368 - INFO -    Offset：[0, 4224, 7680]
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 23:24:34 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas2/h120_labeled.csv
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 23:24:34 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas1/b67_labeled.csv
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3121，校正前pad范围: [0, 3120]，校正后范围: [0, 3120]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3121
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3121
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3121]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3121, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3121，校正前pad范围: [0, 3120]，校正后范围: [0, 3120]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3121
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3121
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3121]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3121, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1277，校正前pad范围: [0, 1276]，校正后范围: [0, 1276]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1277]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1277, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1277，校正前pad范围: [0, 1276]，校正后范围: [0, 1276]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1277]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1277, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1277，校正前pad范围: [0, 1276]，校正后范围: [0, 1276]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1277]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1277, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1277，校正前pad范围: [0, 1276]，校正后范围: [0, 1276]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1277]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1277, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1277，校正前pad范围: [0, 1276]，校正后范围: [0, 1276]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1277]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1277, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1277，校正前pad范围: [0, 1276]，校正后范围: [0, 1276]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1277]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1277, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 576], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 23:24:34 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=407，校正前pad范围: [0, 406]，校正后范围: [0, 406]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 407
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 407
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([407]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([407, 256])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 576], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=407，校正前pad范围: [0, 406]，校正后范围: [0, 406]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 407
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 407
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([407]), 最大索引: 0, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([407, 256])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1277，校正前pad范围: [0, 1276]，校正后范围: [0, 1276]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1277]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1277, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1277，校正前pad范围: [0, 1276]，校正后范围: [0, 1276]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1277
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1277]), 最大索引: 1056, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1277, 128])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3121，校正前pad范围: [0, 3120]，校正后范围: [0, 3120]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3121
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3121
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3121]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3121, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 23:24:34 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3121，校正前pad范围: [0, 3120]，校正后范围: [0, 3120]
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3121
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3121
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3121]), 最大索引: 2112, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3121, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 23:24:34 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 23:24:34 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 23:24:34 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 23:24:34 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 23:24:34 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 23:24:34 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 23:24:34 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 23:24:34 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 23:24:34 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 23:24:34 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 23:24:34 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 23:24:34 - wind_shear:161 - DEBUG - [补点] h120_labeled.csv | 点数3613→3840（384的倍数）
2025-09-20 23:24:34 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 23:24:34 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 23:24:34 - misc:366 - INFO -    各样本点数：[3840, 3840]（均为384的倍数）
2025-09-20 23:24:34 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 23:24:34 - misc:368 - INFO -    Offset：[0, 3840, 7680]
