2025-09-20 17:23:52 - wind_shear:30 - INFO - WindShearDataset train split: 8935 scenes
2025-09-20 17:23:52 - wind_shear:30 - INFO - WindShearDataset val split: 2130 scenes
2025-09-20 17:23:52 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:23:52 - misc:366 - INFO -    各样本点数：[3072, 4608]（均为384的倍数）
2025-09-20 17:23:52 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:23:52 - misc:368 - INFO -    Offset：[0, 3072, 7680]
2025-09-20 17:23:52 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:23:52 - misc:366 - INFO -    各样本点数：[5376, 2304]（均为384的倍数）
2025-09-20 17:23:52 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:23:52 - misc:368 - INFO -    Offset：[0, 5376, 7680]
2025-09-20 17:23:52 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:23:52 - misc:366 - INFO -    各样本点数：[3456, 4224]（均为384的倍数）
2025-09-20 17:23:52 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:23:52 - misc:368 - INFO -    Offset：[0, 3456, 7680]
2025-09-20 17:23:52 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:23:52 - misc:366 - INFO -    各样本点数：[4224, 4608]（均为384的倍数）
2025-09-20 17:23:52 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:23:52 - misc:368 - INFO -    Offset：[0, 4224, 8832]
2025-09-20 17:23:52 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6528
2025-09-20 17:23:52 - misc:366 - INFO -    各样本点数：[3840, 2688]（均为384的倍数）
2025-09-20 17:23:52 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6528, 3])，feat=torch.Size([6528, 9])，label=torch.Size([6528])
2025-09-20 17:23:52 - misc:368 - INFO -    Offset：[0, 3840, 6528]
2025-09-20 17:23:52 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:23:52 - misc:366 - INFO -    各样本点数：[4224, 3840]（均为384的倍数）
2025-09-20 17:23:52 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:23:52 - misc:368 - INFO -    Offset：[0, 4224, 8064]
2025-09-20 17:23:52 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:23:52 - misc:366 - INFO -    各样本点数：[3456, 3840]（均为384的倍数）
2025-09-20 17:23:52 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:23:52 - misc:368 - INFO -    Offset：[0, 3456, 7296]
2025-09-20 17:23:52 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:23:52 - misc:366 - INFO -    各样本点数：[5376, 3456]（均为384的倍数）
2025-09-20 17:23:52 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:23:52 - misc:368 - INFO -    Offset：[0, 5376, 8832]
2025-09-20 17:23:53 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:23:53 - misc:366 - INFO -    各样本点数：[4224, 4608]（均为384的倍数）
2025-09-20 17:23:53 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:23:53 - misc:368 - INFO -    Offset：[0, 4224, 8832]
2025-09-20 17:23:53 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:23:53 - misc:366 - INFO -    各样本点数：[3840, 4224]（均为384的倍数）
2025-09-20 17:23:53 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:23:53 - misc:368 - INFO -    Offset：[0, 3840, 8064]
2025-09-20 17:23:53 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:23:53 - misc:366 - INFO -    各样本点数：[2688, 4992]（均为384的倍数）
2025-09-20 17:23:53 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:23:53 - misc:368 - INFO -    Offset：[0, 2688, 7680]
2025-09-20 17:23:53 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:23:53 - misc:366 - INFO -    各样本点数：[4992, 3840]（均为384的倍数）
2025-09-20 17:23:53 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:23:53 - misc:368 - INFO -    Offset：[0, 4992, 8832]
2025-09-20 17:23:53 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:23:53 - misc:366 - INFO -    各样本点数：[5760, 3840]（均为384的倍数）
2025-09-20 17:23:53 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:23:53 - misc:368 - INFO -    Offset：[0, 5760, 9600]
2025-09-20 17:23:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:23:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:23:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:23:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:23:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:23:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:23:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:23:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:23:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:23:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:23:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:23:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:23:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:23:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:23:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:23:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:23:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:23:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:23:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:23:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:23:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:23:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:23:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:23:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:53 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6912
2025-09-20 17:23:53 - misc:366 - INFO -    各样本点数：[3072, 3840]（均为384的倍数）
2025-09-20 17:23:53 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6912, 3])，feat=torch.Size([6912, 9])，label=torch.Size([6912])
2025-09-20 17:23:53 - misc:368 - INFO -    Offset：[0, 3072, 6912]
2025-09-20 17:23:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:23:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:23:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:23:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:23:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:23:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:23:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3300
2025-09-20 17:23:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3300
2025-09-20 17:23:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3300]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3300, 64])
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:54 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:23:54 - misc:366 - INFO -    各样本点数：[4224, 4992]（均为384的倍数）
2025-09-20 17:23:54 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:23:54 - misc:368 - INFO -    Offset：[0, 4224, 9216]
2025-09-20 17:23:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:23:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3300
2025-09-20 17:23:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3300
2025-09-20 17:23:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3300]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3300, 64])
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:23:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1360]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1360, 128])
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:54 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 17:23:54 - misc:366 - INFO -    各样本点数：[5376, 4608]（均为384的倍数）
2025-09-20 17:23:54 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 17:23:54 - misc:368 - INFO -    Offset：[0, 5376, 9984]
2025-09-20 17:23:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1360]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1360, 128])
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1360]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1360, 128])
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1360]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1360, 128])
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1360]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1360, 128])
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1360]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1360, 128])
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 480], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:23:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:23:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 428
2025-09-20 17:23:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 428
2025-09-20 17:23:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([428]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([428, 256])
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:54 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:23:54 - misc:366 - INFO -    各样本点数：[3072, 4224]（均为384的倍数）
2025-09-20 17:23:54 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:23:54 - misc:368 - INFO -    Offset：[0, 3072, 7296]
2025-09-20 17:23:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 480], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:23:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 428
2025-09-20 17:23:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 428
2025-09-20 17:23:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([428]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([428, 256])
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1360]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1360, 128])
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1360
2025-09-20 17:23:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1360]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1360, 128])
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:23:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3300
2025-09-20 17:23:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3300
2025-09-20 17:23:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3300]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3300, 64])
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:23:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3300
2025-09-20 17:23:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3300
2025-09-20 17:23:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3300]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3300, 64])
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:23:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:23:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:23:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:23:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:23:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:23:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:23:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:23:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:23:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:23:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:23:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:23:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:23:54 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:23:54 - misc:366 - INFO -    各样本点数：[4992, 4608]（均为384的倍数）
2025-09-20 17:23:54 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:23:54 - misc:368 - INFO -    Offset：[0, 4992, 9600]
2025-09-20 17:23:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4992], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4992], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5730
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5730
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5730]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5730, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5730
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5730
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5730]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5730, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2253]), 最大索引: 672, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2253, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2253]), 最大索引: 672, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2253, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2253]), 最大索引: 672, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2253, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2253]), 最大索引: 672, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2253, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2253]), 最大索引: 672, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2253, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2253]), 最大索引: 672, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2253, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 624], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 666
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 666
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([666]), 最大索引: 336, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([666, 256])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 624], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 666
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 666
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([666]), 最大索引: 336, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([666, 256])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2253]), 最大索引: 672, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2253, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2253
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2253]), 最大索引: 672, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2253, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5730
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5730
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5730]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5730, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5730
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5730
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5730]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5730, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4992], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4992], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5501
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5501
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5501]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5501, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5501
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5501
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5501]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5501, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 528], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 625
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 625
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([625]), 最大索引: 480, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([625, 256])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 528], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 625
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 625
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([625]), 最大索引: 480, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([625, 256])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5501
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5501
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5501]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5501, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5501
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5501
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5501]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5501, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:23:55 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:23:55 - misc:366 - INFO -    各样本点数：[4992, 4608]（均为384的倍数）
2025-09-20 17:23:55 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:23:55 - misc:368 - INFO -    Offset：[0, 4992, 9600]
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5061
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5061
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5061]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5061, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5061
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5061
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5061]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5061, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2235]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2235, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2235]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2235, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2235]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2235, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2235]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2235, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2235]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2235, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2235]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2235, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 480], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 697
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 697
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([697]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([697, 256])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 480], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 697
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 697
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([697]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([697, 256])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2235]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2235, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2235
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2235]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2235, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5061
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5061
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5061]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5061, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5061
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5061
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5061]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5061, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6912, unpad长度将设为=6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3456, unpad长度将设为=3456
2025-09-20 17:23:55 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=10368
2025-09-20 17:23:55 - misc:366 - INFO -    各样本点数：[5760, 4608]（均为384的倍数）
2025-09-20 17:23:55 - misc:367 - INFO -    拼接后维度：coord=torch.Size([10368, 3])，feat=torch.Size([10368, 9])，label=torch.Size([10368])
2025-09-20 17:23:55 - misc:368 - INFO -    Offset：[0, 5760, 10368]
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2435
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2435
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2435]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2435, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2435
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2435
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2435]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2435, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1728, unpad长度将设为=1728
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([915]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([915, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([915]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([915, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([915]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([915, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([915]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([915, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([915]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([915, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([915]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([915, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 480], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=864, unpad长度将设为=864
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 294
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 294
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([294]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([294, 256])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 480], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 294
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 294
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([294]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([294, 256])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([915]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([915, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 915
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([915]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([915, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2435
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2435
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2435]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2435, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2435
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2435
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2435]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2435, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:23:55 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:23:55 - misc:366 - INFO -    各样本点数：[4992, 4224]（均为384的倍数）
2025-09-20 17:23:55 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:23:55 - misc:368 - INFO -    Offset：[0, 4992, 9216]
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4608], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4608], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2304], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4512
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4512
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4512]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4512, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2304], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4512
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4512
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4512]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4512, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1248], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 576], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1248], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 610
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 610
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([610]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([610, 256])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1248], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 576], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1248], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 610
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 610
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([610]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([610, 256])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1152], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2496], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1938
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1938]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1938, 128])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2304], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4512
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4512
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4512]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4512, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2304], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4992], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4512
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4512
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4512]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4512, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4608], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:23:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4608], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9984], device='cuda:0')
2025-09-20 17:23:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:23:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:23:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:23:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:23:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:23:55 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:23:55 - misc:366 - INFO -    各样本点数：[1920, 5760]（均为384的倍数）
2025-09-20 17:23:55 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:23:55 - misc:368 - INFO -    Offset：[0, 1920, 7680]
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6563
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6563
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6563]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6563, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6563
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6563
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6563]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6563, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2645]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2645, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2645]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2645, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2645]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2645, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2645]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2645, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2645]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2645, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2645]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2645, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 624], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 801
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 801
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([801]), 最大索引: 528, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([801, 256])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 624], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 801
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 801
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([801]), 最大索引: 528, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([801, 256])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2645]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2645, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2645
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2645]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2645, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6563
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6563
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6563]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6563, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6563
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6563
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6563]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6563, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5259
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5259
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5259]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5259, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5259
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5259
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5259]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5259, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1975]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1975, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1975]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1975, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1975]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1975, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1975]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1975, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1975]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1975, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1975]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1975, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 528], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 571
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 571
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([571]), 最大索引: 384, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([571, 256])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 528], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 571
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 571
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([571]), 最大索引: 384, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([571, 256])
2025-09-20 17:23:56 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=11136
2025-09-20 17:23:56 - misc:366 - INFO -    各样本点数：[4608, 6528]（均为384的倍数）
2025-09-20 17:23:56 - misc:367 - INFO -    拼接后维度：coord=torch.Size([11136, 3])，feat=torch.Size([11136, 9])，label=torch.Size([11136])
2025-09-20 17:23:56 - misc:368 - INFO -    Offset：[0, 4608, 11136]
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1975]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1975, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1975
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1975]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1975, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5259
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5259
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5259]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5259, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5259
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5259
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5259]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5259, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:23:56 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:23:56 - misc:366 - INFO -    各样本点数：[4608, 3072]（均为384的倍数）
2025-09-20 17:23:56 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:23:56 - misc:368 - INFO -    Offset：[0, 4608, 7680]
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7141
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7141
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7141]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7141, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7141
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7141
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7141]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7141, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2963]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2963, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2963]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2963, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2963]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2963, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2963]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2963, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2963]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2963, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2963]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2963, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 900
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 900
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([900]), 最大索引: 624, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([900, 256])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 900
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 900
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([900]), 最大索引: 624, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([900, 256])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2963]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2963, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2963
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2963]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2963, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7141
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7141
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7141]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7141, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7141
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7141
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7141]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7141, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:23:56 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:23:56 - misc:366 - INFO -    各样本点数：[3840, 4992]（均为384的倍数）
2025-09-20 17:23:56 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:23:56 - misc:368 - INFO -    Offset：[0, 3840, 8832]
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4162
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4162
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4162]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4162, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4162
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4162
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4162]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4162, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1737]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1737, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1737]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1737, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1737]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1737, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1737]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1737, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:23:56 - misc:366 - INFO -    各样本点数：[4992, 2304]（均为384的倍数）
2025-09-20 17:23:56 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:23:56 - misc:368 - INFO -    Offset：[0, 4992, 7296]
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1737]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1737, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1737]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1737, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 545
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 545
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([545]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([545, 256])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 545
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 545
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([545]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([545, 256])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1737]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1737, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1737
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1737]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1737, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4162
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4162
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4162]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4162, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4162
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4162
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4162]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4162, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=10368, unpad长度将设为=10368
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 32])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4608], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 32])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5184, unpad长度将设为=5184
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4902
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4902
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4902]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4902, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2304], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4902
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4902
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4902]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4902, 64])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2592, unpad长度将设为=2592
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2123
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2123
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2123]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2123, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2123
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2123
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2123]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2123, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2123
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2123
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2123]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2123, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2123
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2123
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2123]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2123, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2123
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2123
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2123]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2123, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2123
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2123
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2123]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2123, 128])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1296], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 576], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:56 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1296, unpad长度将设为=1296
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1296], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 661
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 661
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([661]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([661, 256])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1296], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 576], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:56 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:56 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1296], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:23:56 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:23:56 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 661
2025-09-20 17:23:56 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 661
2025-09-20 17:23:56 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:56 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:56 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([661]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:56 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:56 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([661, 256])
2025-09-20 17:23:56 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:56 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:56 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:23:56 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2123
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2123
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2123]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2123, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2123
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2123
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2123]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2123, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4902
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4902
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4902]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4902, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:23:57 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:23:57 - misc:366 - INFO -    各样本点数：[3072, 4608]（均为384的倍数）
2025-09-20 17:23:57 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:23:57 - misc:368 - INFO -    Offset：[0, 3072, 7680]
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4902
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4902
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4902]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4902, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4608], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4608], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4112
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4112
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4112]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4112, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4112
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4112
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4112]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4112, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:57 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:23:57 - misc:366 - INFO -    各样本点数：[2304, 3840]（均为384的倍数）
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:23:57 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6144, 3])，feat=torch.Size([6144, 9])，label=torch.Size([6144])
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - misc:368 - INFO -    Offset：[0, 2304, 6144]
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 528], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 518
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 518
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([518]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([518, 256])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 528], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 518
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 518
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([518]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([518, 256])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4112
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4112
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4112]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4112, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4112
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4112
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4112]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4112, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 5760], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 5760], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2880], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5693
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5693
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5693]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5693, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2880], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5693
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5693
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5693]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5693, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1440], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2422]), 最大索引: 480, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2422, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1440], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2422]), 最大索引: 480, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2422, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1440], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2422]), 最大索引: 480, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2422, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1440], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2422]), 最大索引: 480, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2422, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1440], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2422]), 最大索引: 480, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2422, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1440], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2422]), 最大索引: 480, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2422, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 960], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 720], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 960], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 741
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 741
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([741]), 最大索引: 240, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([741, 256])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 960], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 720], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 960], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 741
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 741
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([741]), 最大索引: 240, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([741, 256])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1440], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2422]), 最大索引: 480, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2422, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1440], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2422
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2422]), 最大索引: 480, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2422, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - misc:366 - INFO -    各样本点数：[3456, 4608]（均为384的倍数）
2025-09-20 17:23:57 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:23:57 - misc:368 - INFO -    Offset：[0, 3456, 8064]
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2880], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5693
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5693
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5693]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5693, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2880], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5693
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5693
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5693]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5693, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 5760], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 5760], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4608, 11136], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 6528], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=11136, unpad长度将设为=11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4608, 11136], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(6528, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6528，K=3264
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11136]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11136, 32])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4608, 11136], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 6528], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4608, 11136], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(6528, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6528，K=3264
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11136]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11136, 32])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5568], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3264], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5568, unpad长度将设为=5568
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5568], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3264, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3264，K=816
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5530
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5530
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5530]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5530, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5568], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3264], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5568], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3264, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3264，K=816
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5530
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5530
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5530]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5530, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1632], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2784, unpad长度将设为=2784
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2530]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2530, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1632], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2530]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2530, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1632], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2530]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2530, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1632], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2530]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2530, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1632], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2530]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2530, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1632], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2530]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2530, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1392], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 816], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1392, unpad长度将设为=1392
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1392], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(816, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数816，K=51
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 797
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 797
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([797]), 最大索引: 576, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([797, 256])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1392], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 816], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1392], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(816, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数816，K=51
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 797
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 797
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([797]), 最大索引: 576, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([797, 256])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1632], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2530]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2530, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:23:57 - misc:366 - INFO -    各样本点数：[3456, 4224]（均为384的倍数）
2025-09-20 17:23:57 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:23:57 - misc:368 - INFO -    Offset：[0, 3456, 7680]
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1632], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2784], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2530
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2530]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2530, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5568], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3264], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5568], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3264, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3264，K=816
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5530
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5530
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5530]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5530, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5568], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3264], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5568], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3264, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3264，K=816
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5530
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5530
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5530]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5530, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4608, 11136], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 6528], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4608, 11136], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(6528, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6528，K=1632
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11136]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11136, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  4608, 11136], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 6528], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  4608, 11136], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(6528, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6528，K=1632
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11136
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11136]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11136, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3072], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3072], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1536], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3559
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3559
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3559]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3559, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1536], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3559
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3559
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3559]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3559, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1429]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1429, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1429]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1429, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1429]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1429, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1429]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1429, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1429]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1429, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1429]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1429, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 576, 960], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 384], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:23:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 576, 960], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 436
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 436
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([436]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([436, 256])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 576, 960], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 384], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:23:57 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:23:57 - misc:366 - INFO -    各样本点数：[2304, 4992]（均为384的倍数）
2025-09-20 17:23:57 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:23:57 - misc:368 - INFO -    Offset：[0, 2304, 7296]
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 576, 960], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 436
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 436
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([436]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([436, 256])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1429]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1429, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1429
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1429]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1429, 128])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1536], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3559
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3559
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3559]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3559, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1536], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3559
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3559
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3559]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3559, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3072], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:23:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3072], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:23:57 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:57 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:23:57 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:23:57 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:23:57 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:23:57 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:23:57 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:57 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:58 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:58 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6380
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6380
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6380]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6380, 64])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6380
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6380
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6380]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6380, 64])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:58 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2521]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2521, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2521]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2521, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2521]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2521, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2521]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2521, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2521]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2521, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2521]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2521, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 624], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:58 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 748
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 748
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([748]), 最大索引: 480, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([748, 256])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 624], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 748
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 748
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([748]), 最大索引: 480, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([748, 256])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2521]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2521, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2521
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2521]), 最大索引: 960, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2521, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6380
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6380
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6380]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6380, 64])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6380
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6380
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6380]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6380, 64])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:23:58 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:23:58 - misc:366 - INFO -    各样本点数：[4992, 4608]（均为384的倍数）
2025-09-20 17:23:58 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:23:58 - misc:368 - INFO -    Offset：[0, 4992, 9600]
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 7296], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 2304], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:58 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 7296], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=1152
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 7296], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 2304], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 7296], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=1152
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 3648], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1152], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:58 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 3648], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5317
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5317
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5317]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5317, 64])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 3648], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1152], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 3648], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5317
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5317
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5317]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5317, 64])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  576], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:58 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2130]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2130, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  576], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2130]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2130, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  576], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2130]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2130, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  576], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2130]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2130, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  576], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2130]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2130, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  576], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2130]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2130, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 624, 912], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 288], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 17:23:58 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 624, 912], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(288, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数288，K=18
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 622
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 622
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([622]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([622, 256])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 624, 912], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 288], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 624, 912], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(288, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数288，K=18
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 622
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 622
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([622]), 最大索引: 0, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([622, 256])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  576], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2130]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2130, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  576], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1824], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2130
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2130]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2130, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 3648], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1152], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 3648], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5317
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5317
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5317]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5317, 64])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 3648], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1152], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 3648], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5317
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5317
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5317]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5317, 64])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 7296], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 2304], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 7296], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 7296], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 2304], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 7296], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4608], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:23:58 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4608], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2304], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:23:58 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5204
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5204
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5204]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5204, 64])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2304], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5204
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5204
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5204]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5204, 64])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:58 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1970
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1970
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1970]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1970, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=10368
2025-09-20 17:23:58 - misc:366 - INFO -    各样本点数：[4992, 5376]（均为384的倍数）
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:23:58 - misc:367 - INFO -    拼接后维度：coord=torch.Size([10368, 3])，feat=torch.Size([10368, 9])，label=torch.Size([10368])
2025-09-20 17:23:58 - misc:368 - INFO -    Offset：[0, 4992, 10368]
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1970
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1970
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1970]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1970, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1970
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1970
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1970]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1970, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1970
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1970
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1970]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1970, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1970
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1970
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1970]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1970, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1970
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1970
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1970]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1970, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 576], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:23:58 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 570
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 570
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([570]), 最大索引: 384, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([570, 256])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 576], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 570
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 570
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([570]), 最大索引: 384, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([570, 256])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:23:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:23:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:23:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:23:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1970
2025-09-20 17:23:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1970
2025-09-20 17:23:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:23:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:23:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1970]), 最大索引: 768, 最小索引: 0
2025-09-20 17:23:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:23:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1970, 128])
2025-09-20 17:23:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:23:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:23:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:23:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
